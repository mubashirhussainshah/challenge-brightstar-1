{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "generative_ai_disabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c4acd7ef0944392a5df24a871a667a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c5d2b8a39bc4e3c8e40c2957aa9b63d",
              "IPY_MODEL_fb2236f2ad5f46ba93fc0fdc786056d2",
              "IPY_MODEL_5b4fe311e19f4e50a6d59a3a9a966040"
            ],
            "layout": "IPY_MODEL_15118888aa7b464a9e2577c3ff8dea1a"
          }
        },
        "7c5d2b8a39bc4e3c8e40c2957aa9b63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f11b58370ba47d6a02dcf7fe0539d60",
            "placeholder": "​",
            "style": "IPY_MODEL_095ea811292143a1a22f02d8e4d6941a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fb2236f2ad5f46ba93fc0fdc786056d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c711892958b4b9496b4222f1d611f95",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d57ceb4225e343adbe938e7dd5f91657",
            "value": 59
          }
        },
        "5b4fe311e19f4e50a6d59a3a9a966040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918454d08f314ef0ab6f291892a1cf3c",
            "placeholder": "​",
            "style": "IPY_MODEL_0312f68c33b545d3a8e1bd3f4310b865",
            "value": " 59.0/59.0 [00:00&lt;00:00, 6.80kB/s]"
          }
        },
        "15118888aa7b464a9e2577c3ff8dea1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f11b58370ba47d6a02dcf7fe0539d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095ea811292143a1a22f02d8e4d6941a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c711892958b4b9496b4222f1d611f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57ceb4225e343adbe938e7dd5f91657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918454d08f314ef0ab6f291892a1cf3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0312f68c33b545d3a8e1bd3f4310b865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f469b1ece53e414d9b8405b7f53898ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a6c6191bcbb4b9aa0f7d7decb104b23",
              "IPY_MODEL_5af60f0719b64dec9c888a01f892c766",
              "IPY_MODEL_551ca829c2c24f328c092cd159e0fe75"
            ],
            "layout": "IPY_MODEL_427f3f220f5c4f768e8a2863e10e68c5"
          }
        },
        "4a6c6191bcbb4b9aa0f7d7decb104b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f672655873574b499e96e7aaa7846376",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0027a029cf4438b4640cd25bde11a1",
            "value": "config.json: 100%"
          }
        },
        "5af60f0719b64dec9c888a01f892c766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e3b4d2fabb40e5bffe9d85dc59da39",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_936f009c31254c2a9879e1d7402e3e93",
            "value": 433
          }
        },
        "551ca829c2c24f328c092cd159e0fe75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5119f58087d34263be6348e782ea5858",
            "placeholder": "​",
            "style": "IPY_MODEL_8551b446a9d4438d8173cb426feb4b3e",
            "value": " 433/433 [00:00&lt;00:00, 59.2kB/s]"
          }
        },
        "427f3f220f5c4f768e8a2863e10e68c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f672655873574b499e96e7aaa7846376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0027a029cf4438b4640cd25bde11a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13e3b4d2fabb40e5bffe9d85dc59da39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936f009c31254c2a9879e1d7402e3e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5119f58087d34263be6348e782ea5858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8551b446a9d4438d8173cb426feb4b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "844716b0a90e46a0b80e9904a867e1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf94b09efd949bd9249cf4a4d68c3bd",
              "IPY_MODEL_fa4e9549a19f4487b5aeefc234ecab4d",
              "IPY_MODEL_99710795dbb045279f7752ff0ec9e5f9"
            ],
            "layout": "IPY_MODEL_d6c8741770d44ee19f791f78218f681d"
          }
        },
        "5cf94b09efd949bd9249cf4a4d68c3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2222d4d3f9a24a61b13960adb44429f7",
            "placeholder": "​",
            "style": "IPY_MODEL_e53360a223614d53af7435df196997cd",
            "value": "vocab.txt: "
          }
        },
        "fa4e9549a19f4487b5aeefc234ecab4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38daf208c2094d3b8b9c612edf49a2e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_700c1b2585ec461a92e382f82a1a13bc",
            "value": 1
          }
        },
        "99710795dbb045279f7752ff0ec9e5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c7040d11d5471fb054fb3abecaf315",
            "placeholder": "​",
            "style": "IPY_MODEL_2646a0743a0b4c16bd2214435f3b43b9",
            "value": " 235k/? [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "d6c8741770d44ee19f791f78218f681d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2222d4d3f9a24a61b13960adb44429f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53360a223614d53af7435df196997cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38daf208c2094d3b8b9c612edf49a2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "700c1b2585ec461a92e382f82a1a13bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2c7040d11d5471fb054fb3abecaf315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2646a0743a0b4c16bd2214435f3b43b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9bf57ab8edd464984baf227938cf317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_539845dba27a459ba1d70936fba131b5",
              "IPY_MODEL_4fbda50bfb0e4d6d88d750e9d67c5f1d",
              "IPY_MODEL_8d1bb4a98e0e4890a2af4d3ea0a546fe"
            ],
            "layout": "IPY_MODEL_f69dae6df8c7452db0c9b008e99176a8"
          }
        },
        "539845dba27a459ba1d70936fba131b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c8e42974f9425f86e512cc0fbae7ea",
            "placeholder": "​",
            "style": "IPY_MODEL_8153c9e72335443197f0b279eb2f5d7f",
            "value": "model.safetensors: 100%"
          }
        },
        "4fbda50bfb0e4d6d88d750e9d67c5f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6be7684e33431aa01f0d5fca5c7ab4",
            "max": 445309892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_368200953d3b477cb777e8a47d85a9af",
            "value": 445309892
          }
        },
        "8d1bb4a98e0e4890a2af4d3ea0a546fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7850b8b0cd942fc951f882d22b86703",
            "placeholder": "​",
            "style": "IPY_MODEL_112a6e876796451cab7c551a6cf016d2",
            "value": " 445M/445M [00:02&lt;00:00, 310MB/s]"
          }
        },
        "f69dae6df8c7452db0c9b008e99176a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c8e42974f9425f86e512cc0fbae7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8153c9e72335443197f0b279eb2f5d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af6be7684e33431aa01f0d5fca5c7ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368200953d3b477cb777e8a47d85a9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7850b8b0cd942fc951f882d22b86703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112a6e876796451cab7c551a6cf016d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U optuna transformers[torch] accelerate bitsandbytes scikit-learn seaborn plotly\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/data\"\n",
        "import os\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "os.chdir(DRIVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCJ-a1fSv9x6",
        "outputId": "e22b4e58-1cf7-428a-f5af-ab3ad5cb0fbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m159.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qoQoAj9opVV9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback,\n",
        "    IntervalStrategy\n",
        ")\n",
        "from transformers import DataCollatorWithPadding\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import copy\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Logging\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(message)s\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config class"
      ],
      "metadata": {
        "id": "GNkxtkcKl9-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== CONFIGURATION =====================\n",
        "class Config:\n",
        "    \"\"\"Central configuration for the training pipeline\"\"\"\n",
        "\n",
        "    # Data paths\n",
        "    MAIN_DATA_FILE = \"match_sentences.csv\"\n",
        "    PRIORITY_SCORES_PATH = \"intent_description.json\"\n",
        "    FINAL_TEST_SET_PATH = \"final_test_set.csv\"\n",
        "    FINAL_TRAINVAL_SET_PATH = \"final_trainval_set.csv\"\n",
        "\n",
        "    # Column names\n",
        "    RAW_TEXT_COLUMN = \"text\"\n",
        "    LABEL_COLUMN = \"intent\"\n",
        "    TEST_SIZE = 0.15\n",
        "    SEED = 42\n",
        "\n",
        "    # Model configuration\n",
        "    MODEL_NAME = 'dbmdz/bert-base-italian-xxl-cased'\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # Training hyperparameters (will be optimized)\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 15\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    GRADIENT_CLIP = 1.0\n",
        "\n",
        "    # Advanced training features\n",
        "    USE_CLASS_WEIGHTS = True\n",
        "    USE_PRIORITY_SCORES = False\n",
        "    USE_MIXED_PRECISION = True\n",
        "    USE_FOCAL_LOSS = True\n",
        "    USE_LABEL_SMOOTHING = True\n",
        "    USE_RDROP = False\n",
        "\n",
        "    # Loss function parameters\n",
        "    EARLY_STOPPING_PATIENCE = 10\n",
        "    ALPHA = 0.5  # Balance between class weights and priority\n",
        "    FOCAL_GAMMA = 2.0\n",
        "    LABEL_SMOOTHING = 0.05\n",
        "\n",
        "    # Cross-validation and hyperparameter tuning\n",
        "    K_FOLDS = 5\n",
        "    OPTUNA_N_TRIALS = 30\n",
        "    OPTUNA_TIMEOUT = None  # Optional timeout in seconds\n",
        "    USE_PRUNING = True\n",
        "\n",
        "    # INFERENCE PARAMETERS\n",
        "    TEMPERATURE = 0.8\n",
        "    CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "    # Output paths\n",
        "    MODEL_SAVE_PATH = \"italian_intent_model\"\n",
        "    PLOT_SAVE_PATH = \"training_plots\"\n",
        "    CHECKPOINT_DIR = \"checkpoints\"\n",
        "    BEST_PARAMS_PATH = \"best_hyperparameters.json\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Config(LR={self.LEARNING_RATE:.2e}, BS={self.BATCH_SIZE}, WD={self.WEIGHT_DECAY:.2f})\"\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Convert config to dictionary for saving\"\"\"\n",
        "        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\"Save configuration to JSON\"\"\"\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2)"
      ],
      "metadata": {
        "id": "vuBU-MzzplgC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset class"
      ],
      "metadata": {
        "id": "v9kfRHpRl65i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== DATASET =====================\n",
        "class IntentDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that holds raw text and tokenizes on-the-fly.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts: List[str], labels: List[int], tokenizer: AutoTokenizer, max_len: int):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize only this specific sample\n",
        "        # padding=False. DataCollator will pad the batch later.\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=False,\n",
        "            return_tensors=None # standard lists, not tensor\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': encoding['input_ids'],\n",
        "            'attention_mask': encoding['attention_mask'],\n",
        "            'labels': label\n",
        "        }\n",
        "\n",
        "        if 'token_type_ids' in encoding:\n",
        "            item['token_type_ids'] = encoding['token_type_ids']\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "id": "rN57-tjDpouw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss related functions"
      ],
      "metadata": {
        "id": "ofN1Rvoul2Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== LOSS FUNCTIONS =====================\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss for multi-class classification with priority weighting.\n",
        "\n",
        "    Features:\n",
        "    - Focuses on hard examples (reduces loss for easy examples)\n",
        "    - Supports class weighting (alpha)\n",
        "    - Optional label smoothing for regularization\n",
        "\n",
        "    Paper: \"Focal Loss for Dense Object Detection\" (Lin et al., 2017)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        alpha: Optional[torch.Tensor] = None,\n",
        "        gamma: float = 2.0,\n",
        "        reduction: str = 'mean',\n",
        "        label_smoothing: float = 0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: Logits [batch_size, num_classes]\n",
        "            targets: True labels [batch_size]\n",
        "        \"\"\"\n",
        "        # Compute cross-entropy with label smoothing\n",
        "        ce_loss = torch.nn.functional.cross_entropy(\n",
        "            inputs,\n",
        "            targets,\n",
        "            reduction='none',\n",
        "            label_smoothing=self.label_smoothing\n",
        "        )\n",
        "\n",
        "        # Get probabilities\n",
        "        p = torch.nn.functional.softmax(inputs, dim=1)\n",
        "        p_t = p.gather(1, targets.view(-1, 1)).squeeze(1)\n",
        "\n",
        "        # Focal weight: (1 - p_t)^gamma\n",
        "        focal_weight = (1 - p_t) ** self.gamma\n",
        "\n",
        "        # Apply class weights (alpha)\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.device != inputs.device:\n",
        "                self.alpha = self.alpha.to(inputs.device)\n",
        "            alpha_t = self.alpha.gather(0, targets)\n",
        "            focal_loss = alpha_t * focal_weight * ce_loss\n",
        "        else:\n",
        "            focal_loss = focal_weight * ce_loss\n",
        "\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ],
      "metadata": {
        "id": "mrxE_uB1prPX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== TRAINER =====================\n",
        "class FocalTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Enhanced trainer with:\n",
        "    - Focal loss\n",
        "    - Priority weighting\n",
        "    - Label smoothing\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        loss_weights: Optional[torch.Tensor] = None,\n",
        "        gamma: float = 2.0,\n",
        "        label_smoothing: float = 0.0,\n",
        "        use_focal_loss: bool = True,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_weights = loss_weights\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "        self.use_focal_loss = use_focal_loss\n",
        "\n",
        "        # Initialize loss functions\n",
        "        if self.use_focal_loss:\n",
        "            self.loss_fn = FocalLoss(\n",
        "                alpha=loss_weights,\n",
        "                gamma=gamma,\n",
        "                reduction='mean',\n",
        "                label_smoothing=label_smoothing\n",
        "            )\n",
        "            logging.info(f\"Using Focal Loss (γ={gamma}, smoothing={label_smoothing})\")\n",
        "        else:\n",
        "            self.loss_fn = None\n",
        "            logging.info(f\"Using Weighted CrossEntropy\")\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        # Standard forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Compute base loss\n",
        "        if self.use_focal_loss and self.loss_fn is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "        else:\n",
        "            if self.loss_weights is not None:\n",
        "                if self.loss_weights.device != logits.device:\n",
        "                    self.loss_weights = self.loss_weights.to(logits.device)\n",
        "                loss_fct = torch.nn.CrossEntropyLoss(\n",
        "                    weight=self.loss_weights,\n",
        "                    label_smoothing=self.label_smoothing\n",
        "                )\n",
        "            else:\n",
        "                loss_fct = torch.nn.CrossEntropyLoss(label_smoothing=self.label_smoothing)\n",
        "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "TTZYPYccpt_y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class RDropTrainer(FocalTrainer):\n",
        "    \"\"\"\n",
        "    Trainer with R-Drop regularization (Simultaneously minimizes CE and KL-Divergence).\n",
        "    Paper: https://arxiv.org/abs/2106.14448\n",
        "    \"\"\"\n",
        "    def __init__(self, rdrop_alpha: float = 4.0, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.rdrop_alpha = rdrop_alpha\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        if return_outputs:\n",
        "            # During evaluation/inference, we don't need R-Drop\n",
        "            return super().compute_loss(model, inputs, return_outputs)\n",
        "\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        # Forward pass 1\n",
        "        outputs1 = model(**inputs)\n",
        "        logits1 = outputs1.get(\"logits\")\n",
        "\n",
        "        # Forward pass 2\n",
        "        outputs2 = model(**inputs)\n",
        "        logits2 = outputs2.get(\"logits\")\n",
        "\n",
        "        # We use the internal loss_fn (Focal) if available, otherwise standard CE\n",
        "        if self.use_focal_loss and self.loss_fn is not None:\n",
        "            loss1 = self.loss_fn(logits1, labels)\n",
        "            loss2 = self.loss_fn(logits2, labels)\n",
        "            ce_loss = (loss1 + loss2) / 2\n",
        "        else:\n",
        "            # Reconstruct standard loss function if Focal is off\n",
        "            loss_fct = torch.nn.CrossEntropyLoss(\n",
        "                weight=self.loss_weights,\n",
        "                label_smoothing=self.label_smoothing\n",
        "            )\n",
        "            ce_loss = (loss_fct(logits1, labels) + loss_fct(logits2, labels)) / 2\n",
        "\n",
        "        # KL Divergence (Consistency loss)\n",
        "        # We want the predictions of Pass 1 to be close to Pass 2, and vice versa.\n",
        "        # No .detach() ensures gradients flow through both to align them.\n",
        "        p1 = F.log_softmax(logits1, dim=-1)\n",
        "        p2 = F.log_softmax(logits2, dim=-1)\n",
        "\n",
        "        # kl_div(input, target) -> divergence of input FROM target\n",
        "        kl_loss = (\n",
        "            F.kl_div(p1, p2, reduction='batchmean', log_target=True) +\n",
        "            F.kl_div(p2, p1, reduction='batchmean', log_target=True)\n",
        "        ) / 2\n",
        "\n",
        "        # Final loss\n",
        "        loss = ce_loss + (self.rdrop_alpha * kl_loss)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Gi9yvP-XwgSN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Utilities =====================\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Enhanced metrics computation\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1_macro = f1_score(labels, predictions, average=\"macro\", zero_division=0)\n",
        "    f1_weighted = f1_score(labels, predictions, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1_weighted,\n",
        "        \"f1_macro\": f1_macro\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_loss_weights(\n",
        "    labels: List[int],\n",
        "    json_path: str,\n",
        "    id2label: Dict[int, str],\n",
        "    num_labels: int,\n",
        "    use_balance: bool = True,\n",
        "    use_priority: bool = True,\n",
        "    alpha: float = 0.5\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes combined weights for loss function.\n",
        "\n",
        "    Args:\n",
        "        alpha: 0=priority only, 1=balance only, 0.5=equal mix\n",
        "    \"\"\"\n",
        "    balance_weights = np.ones(num_labels, dtype=np.float32)\n",
        "    priority_weights = np.ones(num_labels, dtype=np.float32)\n",
        "\n",
        "    # Class balance weights\n",
        "    if use_balance:\n",
        "        counts = np.bincount(labels, minlength=num_labels)\n",
        "        safe_counts = np.where(counts == 0, 1, counts)\n",
        "        total = len(labels)\n",
        "        balance_weights = total / (num_labels * safe_counts.astype(np.float32))\n",
        "        balance_weights = normalize_weights(balance_weights, min_val=0.5, max_val=2.0)\n",
        "        logging.info(f\"Class balance weights: {balance_weights.min():.3f} - {balance_weights.max():.3f}\")\n",
        "\n",
        "    # Priority weights\n",
        "    if use_priority and os.path.exists(json_path):\n",
        "        with open(json_path, 'r') as f:\n",
        "            descriptions = json.load(f)\n",
        "        priority_map = {item['intent']: item['priority'] for item in descriptions}\n",
        "        priorities = np.array([priority_map.get(id2label[i], 50) for i in range(num_labels)])\n",
        "        priority_weights = 0.5 + 1.5 * (priorities / 100.0)\n",
        "        logging.info(f\"Priority weights: {priority_weights.min():.3f} - {priority_weights.max():.3f}\")\n",
        "\n",
        "    # Combine weights\n",
        "    if use_balance and use_priority:\n",
        "        final_weights = alpha * balance_weights + (1 - alpha) * priority_weights\n",
        "        logging.info(f\"Combined weights (α={alpha:.2f})\")\n",
        "    elif use_balance:\n",
        "        final_weights = balance_weights\n",
        "    elif use_priority:\n",
        "        final_weights = priority_weights\n",
        "    else:\n",
        "        final_weights = np.ones(num_labels, dtype=np.float32)\n",
        "\n",
        "    # Normalize to mean=1.0 and clip extremes\n",
        "    final_weights = final_weights / final_weights.mean()\n",
        "    final_weights = np.clip(final_weights, 0.1, 10.0)\n",
        "\n",
        "    logging.info(f\"Final weights: {final_weights.min():.3f} - {final_weights.max():.3f}\")\n",
        "\n",
        "    return torch.tensor(final_weights, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def normalize_weights(weights: np.ndarray, min_val: float = 0.5, max_val: float = 2.0) -> np.ndarray:\n",
        "    \"\"\"Min-max normalization to [min_val, max_val]\"\"\"\n",
        "    w_min, w_max = weights.min(), weights.max()\n",
        "    if w_max - w_min < 1e-6:\n",
        "        return np.ones_like(weights) * ((min_val + max_val) / 2)\n",
        "    normalized = (weights - w_min) / (w_max - w_min)\n",
        "    return min_val + (max_val - min_val) * normalized\n",
        "\n",
        "\n",
        "def tokenize_data(\n",
        "    tokenizer: AutoTokenizer,\n",
        "    texts: List[str],\n",
        "    labels: List[int],\n",
        "    max_len: int\n",
        ") -> Tuple[Dict, List[int]]:\n",
        "    \"\"\"Tokenize texts for model input\"\"\"\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=None\n",
        "    )\n",
        "    return encodings, labels"
      ],
      "metadata": {
        "id": "HPa4wiIapxSH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load and preparation utility"
      ],
      "metadata": {
        "id": "yiOAPOG9lwaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Data preparation =====================\n",
        "def load_and_prep_data(config: Config) -> Tuple[pd.DataFrame, pd.DataFrame, Dict, Dict, int]:\n",
        "    \"\"\"Load and prepare dataset with stratified split\"\"\"\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(\"LOADING DATASET\")\n",
        "    logging.info(\"=\" * 70)\n",
        "\n",
        "    # Read and sanitize dataset\n",
        "    df = pd.read_csv(config.MAIN_DATA_FILE)\n",
        "    df = df.dropna(subset=[config.RAW_TEXT_COLUMN, config.LABEL_COLUMN])\n",
        "    df[config.RAW_TEXT_COLUMN] = df[config.RAW_TEXT_COLUMN].astype(str).str.strip()\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    logging.info(f\"Loaded {len(df)} samples\")\n",
        "\n",
        "    # Stratified split\n",
        "    df_trainval, df_test = train_test_split(\n",
        "            df,\n",
        "            test_size=config.TEST_SIZE,\n",
        "            random_state=config.SEED,\n",
        "            stratify=df[config.LABEL_COLUMN]\n",
        "    )\n",
        "\n",
        "    # Create label mappings\n",
        "    target_intents = sorted(df[config.LABEL_COLUMN].unique())\n",
        "    num_labels = len(target_intents)\n",
        "    label2id = {label: i for i, label in enumerate(target_intents)}\n",
        "    id2label = {i: label for i, label in enumerate(target_intents)}\n",
        "    logging.info(f\"Model will train on {num_labels} valid intents.\")\n",
        "\n",
        "    # Show distribution\n",
        "    intent_counts = df[config.LABEL_COLUMN].value_counts()\n",
        "    logging.info(f\"\\n{num_labels} intents found:\")\n",
        "    for intent, count in intent_counts.head(10).items():\n",
        "        logging.info(f\"  {intent[:50]:50s} : {count:4d} ({count/len(df)*100:5.2f}%)\")\n",
        "\n",
        "    df_trainval['labels'] = df_trainval[config.LABEL_COLUMN].map(label2id)\n",
        "    df_test['labels'] = df_test[config.LABEL_COLUMN].map(label2id)\n",
        "\n",
        "    # Save splits\n",
        "    df_trainval.to_csv(config.FINAL_TRAINVAL_SET_PATH, index=False)\n",
        "    df_test.to_csv(config.FINAL_TEST_SET_PATH, index=False)\n",
        "\n",
        "    logging.info(f\"\\nTrain/Val: {len(df_trainval)} | Test: {len(df_test)}\")\n",
        "\n",
        "    return df_trainval, df_test, label2id, id2label, num_labels"
      ],
      "metadata": {
        "id": "nGLOeWM5pzxf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and hyperparameter optimization"
      ],
      "metadata": {
        "id": "VKb0rx-Elqpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Training =====================\n",
        "def finetune_model(\n",
        "    config: Config,\n",
        "    tokenizer: AutoTokenizer,\n",
        "    train_texts: List[str],\n",
        "    train_labels: List[int],\n",
        "    val_texts: List[str],\n",
        "    val_labels: List[int],\n",
        "    label2id: Dict,\n",
        "    id2label: Dict,\n",
        "    num_labels: int,\n",
        "    main_model: Optional[AutoModelForSequenceClassification] = None,\n",
        "    fold_id: str = \"0\",\n",
        "    save_model: bool = False,\n",
        "    model_save_path: Optional[str] = None\n",
        ") -> float:\n",
        "    \"\"\"Train model on a single fold\"\"\"\n",
        "    logging.info(f\"Training Fold {fold_id}...\")\n",
        "\n",
        "    train_dataset = IntentDataset(train_texts, train_labels, tokenizer, config.MAX_LEN)\n",
        "    val_dataset = IntentDataset(val_texts, val_labels, tokenizer, config.MAX_LEN)\n",
        "\n",
        "    if main_model is not None:\n",
        "        model = copy.deepcopy(main_model)\n",
        "    else:\n",
        "        # Load from disk (fallback)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            config.MODEL_NAME,\n",
        "            num_labels=num_labels,\n",
        "            id2label=id2label,\n",
        "            label2id=label2id\n",
        "        )\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Compute loss weights\n",
        "    final_weights = None\n",
        "    if config.USE_CLASS_WEIGHTS or config.USE_PRIORITY_SCORES:\n",
        "        final_weights = compute_loss_weights(\n",
        "            labels=train_labels,\n",
        "            json_path=config.PRIORITY_SCORES_PATH,\n",
        "            id2label=id2label,\n",
        "            num_labels=num_labels,\n",
        "            use_balance=config.USE_CLASS_WEIGHTS,\n",
        "            use_priority=config.USE_PRIORITY_SCORES,\n",
        "            alpha=config.ALPHA\n",
        "        )\n",
        "\n",
        "    # Training arguments\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"{config.CHECKPOINT_DIR}/fold_{fold_id}\",\n",
        "        overwrite_output_dir=True,\n",
        "        eval_strategy=IntervalStrategy.EPOCH,\n",
        "        save_strategy=\"no\",\n",
        "        learning_rate=config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=config.BATCH_SIZE,\n",
        "        num_train_epochs=config.EPOCHS,\n",
        "        weight_decay=config.WEIGHT_DECAY,\n",
        "        warmup_ratio=config.WARMUP_RATIO,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        load_best_model_at_end=False,\n",
        "        greater_is_better=True,\n",
        "        fp16=config.USE_MIXED_PRECISION,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        disable_tqdm=False\n",
        "    )\n",
        "\n",
        "    # Select trainer class\n",
        "    data_collator = DataCollatorWithPadding(tokenizer, padding=True)\n",
        "    TrainerClass = RDropTrainer if config.USE_RDROP else FocalTrainer\n",
        "\n",
        "    trainer = TrainerClass(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=config.EARLY_STOPPING_PATIENCE)],\n",
        "        loss_weights=final_weights,\n",
        "        gamma=config.FOCAL_GAMMA,\n",
        "        label_smoothing=config.LABEL_SMOOTHING,\n",
        "        use_focal_loss=config.USE_FOCAL_LOSS\n",
        "        #rdrop_alpha=5.0\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer.train()\n",
        "\n",
        "    # Get best F1\n",
        "    log_history = trainer.state.log_history\n",
        "    eval_f1_scores = [entry['eval_f1'] for entry in log_history if 'eval_f1' in entry]\n",
        "    best_f1 = max(eval_f1_scores) if eval_f1_scores else trainer.evaluate()[\"eval_f1\"]\n",
        "\n",
        "    logging.info(f\"Fold {fold_id}: Best F1 = {best_f1:.4f}\")\n",
        "\n",
        "    if save_model and model_save_path:\n",
        "        trainer.save_model(model_save_path)\n",
        "        tokenizer.save_pretrained(model_save_path)\n",
        "        logging.info(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_f1\n"
      ],
      "metadata": {
        "id": "BP8IjeV_p1gH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Optuna Hyperparameter Search =====================\n",
        "def run_hp_search_optuna(\n",
        "    config: Config,\n",
        "    df_trainval: pd.DataFrame,\n",
        "    label2id: Dict,\n",
        "    id2label: Dict,\n",
        "    num_labels: int,\n",
        "    text_column: str\n",
        ") -> Tuple[Config, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Optuna hyperparameter search with:\n",
        "    - Pruning for efficiency\n",
        "    - Better search space\n",
        "    \"\"\"\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(f\"OPTUNA HYPERPARAMETER SEARCH ({config.OPTUNA_N_TRIALS} trials)\")\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(\"Loading main Model and tokenizer into CPU memory...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
        "\n",
        "    main_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        config.MODEL_NAME,\n",
        "        num_labels=num_labels,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    main_model.cpu()\n",
        "\n",
        "    # Create cached datasets\n",
        "    X = df_trainval[text_column].tolist()\n",
        "    y = df_trainval['labels'].tolist()\n",
        "\n",
        "    logging.info(\"Assets loaded. Starting Optimization.\")\n",
        "\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        \"\"\"Objective function with expanded search space\"\"\"\n",
        "\n",
        "        # Sample hyperparameters\n",
        "        trial_config = copy.deepcopy(config)\n",
        "\n",
        "        # Core hyperparameters\n",
        "        trial_config.LEARNING_RATE = trial.suggest_float(\"learning_rate\", 5e-6, 5e-5, log=True)\n",
        "        trial_config.BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [16, 24, 32])\n",
        "        trial_config.WEIGHT_DECAY = trial.suggest_float(\"weight_decay\", 0.0, 0.15)\n",
        "        trial_config.WARMUP_RATIO = trial.suggest_float(\"warmup_ratio\", 0.05, 0.2)\n",
        "\n",
        "        # Loss function parameters\n",
        "        if config.USE_CLASS_WEIGHTS and config.USE_PRIORITY_SCORES:\n",
        "            trial_config.ALPHA = trial.suggest_float(\"alpha\", 0.2, 0.8)\n",
        "\n",
        "        if config.USE_FOCAL_LOSS:\n",
        "            trial_config.FOCAL_GAMMA = trial.suggest_float(\"focal_gamma\", 0.5, 3.0)\n",
        "            trial_config.LABEL_SMOOTHING = trial.suggest_float(\"label_smoothing\", 0.0, 0.1)\n",
        "\n",
        "        # K-Fold cross-validation\n",
        "        skf = StratifiedKFold(n_splits=config.K_FOLDS, shuffle=True, random_state=42)\n",
        "        fold_f1_scores = []\n",
        "\n",
        "        try:\n",
        "            for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "                train_texts = [X[i] for i in train_idx]\n",
        "                train_labels = [y[i] for i in train_idx]\n",
        "                val_texts = [X[i] for i in val_idx]\n",
        "                val_labels = [y[i] for i in val_idx]\n",
        "\n",
        "                fold_id = f\"T{trial.number}_F{fold+1}\"\n",
        "\n",
        "                # Train fold\n",
        "                fold_f1 = finetune_model(\n",
        "                    config=trial_config,\n",
        "                    tokenizer=tokenizer,\n",
        "                    train_texts=train_texts,\n",
        "                    train_labels=train_labels,\n",
        "                    val_texts=val_texts,\n",
        "                    val_labels=val_labels,\n",
        "                    label2id=label2id,\n",
        "                    id2label=id2label,\n",
        "                    num_labels=num_labels,\n",
        "                    main_model=main_model,\n",
        "                    fold_id=fold_id,\n",
        "                    save_model=False\n",
        "                )\n",
        "                fold_f1_scores.append(fold_f1)\n",
        "\n",
        "                # Cleanup\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # Optuna pruning (stop bad trials early)\n",
        "                if config.USE_PRUNING:\n",
        "                    current_avg_f1 = np.mean(fold_f1_scores)\n",
        "                    trial.report(current_avg_f1, step=fold)\n",
        "                    if trial.should_prune():\n",
        "                        logging.info(f\"Pruning Trial {trial.number} at Fold {fold+1}\")\n",
        "                        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        except optuna.exceptions.TrialPruned:\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Trial {trial.number} failed: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "        # Calculate average F1\n",
        "        avg_f1 = np.mean(fold_f1_scores)\n",
        "        std_f1 = np.std(fold_f1_scores)\n",
        "\n",
        "        logging.info(f\"Trial {trial.number}: F1={avg_f1:.4f} ± {std_f1:.4f}\")\n",
        "\n",
        "        return avg_f1\n",
        "\n",
        "    # Create Optuna study with pruning\n",
        "    pruner = optuna.pruners.MedianPruner(\n",
        "        n_startup_trials=5,\n",
        "        n_warmup_steps=2,\n",
        "        interval_steps=1\n",
        "    ) if config.USE_PRUNING else optuna.pruners.NopPruner()\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        pruner=pruner,\n",
        "        study_name=\"bert_intent_classification\"\n",
        "    )\n",
        "\n",
        "    # Run optimization\n",
        "    study.optimize(\n",
        "        objective,\n",
        "        n_trials=config.OPTUNA_N_TRIALS,\n",
        "        timeout=config.OPTUNA_TIMEOUT,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Report results\n",
        "    logging.info(f\"\\n{'=' * 70}\")\n",
        "    logging.info(\"OPTIMIZATION COMPLETE\")\n",
        "    logging.info(f\"{'=' * 70}\")\n",
        "    logging.info(f\"Best Trial: {study.best_trial.number}\")\n",
        "    logging.info(f\"Best F1: {study.best_value:.4f}\")\n",
        "    logging.info(f\"Best Params:\")\n",
        "    for key, value in study.best_params.items():\n",
        "        logging.info(f\"  {key}: {value}\")\n",
        "    logging.info(f\"{'=' * 70}\\n\")\n",
        "\n",
        "    # Update config with best params\n",
        "    best_config = copy.deepcopy(config)\n",
        "    for param, value in study.best_params.items():\n",
        "        if hasattr(best_config, param.upper()):\n",
        "            setattr(best_config, param.upper(), value)\n",
        "        else:\n",
        "            # Handle nested parameters\n",
        "            param_map = {\n",
        "                \"learning_rate\": \"LEARNING_RATE\",\n",
        "                \"batch_size\": \"BATCH_SIZE\",\n",
        "                \"weight_decay\": \"WEIGHT_DECAY\",\n",
        "                \"warmup_ratio\": \"WARMUP_RATIO\",\n",
        "                \"alpha\": \"ALPHA\",\n",
        "                \"focal_gamma\": \"FOCAL_GAMMA\",\n",
        "                \"label_smoothing\": \"LABEL_SMOOTHING\",\n",
        "\n",
        "            }\n",
        "            if param in param_map:\n",
        "                setattr(best_config, param_map[param], value)\n",
        "\n",
        "    # Save best hyperparameters\n",
        "    with open(config.BEST_PARAMS_PATH, 'w') as f:\n",
        "        json.dump(study.best_params, f, indent=2)\n",
        "    logging.info(f\"Best params saved to {config.BEST_PARAMS_PATH}\")\n",
        "\n",
        "    # Save trials dataframe\n",
        "    trials_df = study.trials_dataframe()\n",
        "    trials_df.to_csv(\"optuna_trials.csv\", index=False)\n",
        "    logging.info(f\"Trials saved to optuna_trials.csv\")\n",
        "\n",
        "    return best_config, trials_df\n"
      ],
      "metadata": {
        "id": "kZZI2lbLp4jP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Final Model Training =====================\n",
        "def train_final_model(\n",
        "    config: Config,\n",
        "    df_trainval: pd.DataFrame,\n",
        "    label2id: Dict,\n",
        "    id2label: Dict,\n",
        "    num_labels: int,\n",
        "    text_column: str,\n",
        "    model_save_suffix: str = \"\"\n",
        ") -> str:\n",
        "    \"\"\"Train final model on full trainval set with best hyperparameters\"\"\"\n",
        "    model_save_path = f\"{config.MODEL_SAVE_PATH}{model_save_suffix}\"\n",
        "\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(\"TRAINING FINAL MODEL\")\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(f\"Using optimized hyperparameters:\")\n",
        "    logging.info(f\"  LR={config.LEARNING_RATE:.2e}, BS={config.BATCH_SIZE}, WD={config.WEIGHT_DECAY:.3f}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
        "\n",
        "    # Internal train/val split for early stopping\n",
        "    train_df, val_df = train_test_split(\n",
        "        df_trainval,\n",
        "        test_size=0.1,\n",
        "        random_state=42,\n",
        "        stratify=df_trainval['labels']\n",
        "    )\n",
        "\n",
        "    train_texts = train_df[text_column].tolist()\n",
        "    train_labels = train_df['labels'].tolist()\n",
        "    val_texts = val_df[text_column].tolist()\n",
        "    val_labels = val_df['labels'].tolist()\n",
        "\n",
        "    best_f1 = finetune_model(\n",
        "        config=config,\n",
        "        tokenizer=tokenizer,\n",
        "        train_texts=train_texts,\n",
        "        train_labels=train_labels,\n",
        "        val_texts=val_texts,\n",
        "        val_labels=val_labels,\n",
        "        label2id=label2id,\n",
        "        id2label=id2label,\n",
        "        num_labels=num_labels,\n",
        "        fold_id=\"FINAL\",\n",
        "        save_model=True,\n",
        "        model_save_path=model_save_path\n",
        "    )\n",
        "\n",
        "    logging.info(f\"Final model training complete. Val F1: {best_f1:.4f}\")\n",
        "    logging.info(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "    # Save configuration\n",
        "    config.save(f\"{model_save_path}/training_config.json\")\n",
        "\n",
        "    return model_save_path"
      ],
      "metadata": {
        "id": "aDWukDvIqBSI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference and final eval"
      ],
      "metadata": {
        "id": "ZAlbnua8lmDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InferencePipeline:\n",
        "    \"\"\"\n",
        "    Optimized inference class that loads the model once and stays in memory.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path: str, device: str = None):\n",
        "        self.model_path = model_path\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        logging.info(f\"Loading inference model from {model_path} to {self.device}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        logging.info(\"Model loaded successfully.\")\n",
        "\n",
        "    # def predict(self, text: str, threshold: float = 0.7) -> Dict[str, any]:\n",
        "    #     \"\"\"Predict intent for a single text string.\"\"\"\n",
        "    #     inputs = self.tokenizer(\n",
        "    #         text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128\n",
        "    #     ).to(self.device)\n",
        "    #\n",
        "    #     with torch.no_grad():\n",
        "    #         outputs = self.model(**inputs)\n",
        "    #         probs = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
        "    #         # probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    #         confidence, predicted_class = torch.max(probs, dim=1)\n",
        "    #\n",
        "    #     predicted_label = self.model.config.id2label[predicted_class.item()]\n",
        "    #\n",
        "    #     return {\n",
        "    #         'text': text,\n",
        "    #         'intent': predicted_label,\n",
        "    #         'confidence': float(confidence.item()),\n",
        "    #         'probabilities': probs[0].cpu().numpy()  # All class probabilities\n",
        "    #     }\n",
        "\n",
        "    def predict_batch(\n",
        "        self,\n",
        "        texts: List[str],\n",
        "        batch_size: int = 32,\n",
        "        temperature: float = 1.0,\n",
        "        threshold: float = 0.7,\n",
        "        return_confidences: bool = False\n",
        "    ) -> Tuple[List[str], List[int], Optional[np.ndarray]]:\n",
        "        \"\"\"\n",
        "        Batch prediction optimized for test set evaluation.\n",
        "\n",
        "        Args:\n",
        "            texts: List of input texts\n",
        "            batch_size: Batch size for inference\n",
        "            return_confidences: If True, also return confidence scores\n",
        "\n",
        "        Returns:\n",
        "            predicted_labels: List of predicted intent labels\n",
        "            all_preds_ids: List of predicted class IDs\n",
        "            confidences: (Optional) Array of confidence scores\n",
        "        \"\"\"\n",
        "        all_preds_ids = []\n",
        "        all_confidences = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Inference Batch\"):\n",
        "            batch_texts = texts[i : i + batch_size]\n",
        "            inputs = self.tokenizer(\n",
        "                batch_texts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128\n",
        "            ).to(self.device)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                scaled_logits = outputs.logits / temperature\n",
        "                probs = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
        "                confidences, predictions = torch.max(probs, dim=-1)\n",
        "\n",
        "                all_preds_ids.extend(predictions.cpu().numpy())\n",
        "                all_confidences.extend(confidences.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "\n",
        "        predicted_labels = []\n",
        "        for idx, conf in zip(all_preds_ids, all_confidences):\n",
        "            if conf < threshold:\n",
        "                predicted_labels.append(\"NOMATCH\")\n",
        "            else:\n",
        "                predicted_labels.append(self.model.config.id2label[idx])\n",
        "\n",
        "        if return_confidences:\n",
        "            return predicted_labels, all_preds_ids, np.array(all_confidences), np.array(all_probs)\n",
        "        else:\n",
        "            return predicted_labels, all_preds_ids\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uOjd5hBdqDln"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation\n",
        "def evaluate_on_test_set(\n",
        "    config: Config,\n",
        "    df_test: pd.DataFrame,\n",
        "    model_path: str,\n",
        "    label2id: Dict,\n",
        "    id2label: Dict,\n",
        "    num_labels: int,\n",
        "    text_column: str,\n",
        "    report_suffix: str = \"\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate using the InferencePipeline class (batch mode).\n",
        "    \"\"\"\n",
        "    logging.info(\"\\n\" + \"=\" * 70)\n",
        "    logging.info(\"FINAL EVALUATION ON TEST SET\")\n",
        "    logging.info(\"=\" * 70)\n",
        "\n",
        "    pipeline = InferencePipeline(model_path=model_path)\n",
        "\n",
        "    test_texts = df_test[text_column].tolist()\n",
        "    true_labels = df_test[config.LABEL_COLUMN].tolist()\n",
        "\n",
        "    logging.info(f\"Running inference on {len(test_texts)} samples...\")\n",
        "\n",
        "    # Get predictions with confidences\n",
        "    pred_labels, pred_ids, confidences, all_probs = pipeline.predict_batch(\n",
        "        test_texts,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        temperature=config.TEMPERATURE,\n",
        "        threshold=config.CONFIDENCE_THRESHOLD,\n",
        "        return_confidences=True\n",
        "    )\n",
        "    unique_labels = sorted(list(set(true_labels + pred_labels)))\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_acc = accuracy_score(true_labels, pred_labels)\n",
        "    test_f1 = f1_score(true_labels, pred_labels, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    logging.info(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "    logging.info(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    target_names = [id2label[i] for i in range(num_labels)]\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "    print(\"=\" * 70)\n",
        "    print(classification_report(\n",
        "        true_labels, pred_labels,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    # ============================================================\n",
        "    # CONFIDENCE STATISTICS\n",
        "    # ============================================================\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"CONFIDENCE STATISTICS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Mean Confidence:   {np.mean(confidences):.4f}\")\n",
        "    print(f\"Median Confidence: {np.median(confidences):.4f}\")\n",
        "    print(f\"Std Confidence:    {np.std(confidences):.4f}\")\n",
        "    print(f\"Min Confidence:    {np.min(confidences):.4f}\")\n",
        "    print(f\"Max Confidence:    {np.max(confidences):.4f}\")\n",
        "\n",
        "    # Confidence distribution\n",
        "    print(\"\\nConfidence Distribution:\")\n",
        "    conf_ranges = [\n",
        "        (\"Very High (>0.90)\", np.sum(confidences > 0.90)),\n",
        "        (\"High (0.80-0.90)\", np.sum((confidences >= 0.80) & (confidences <= 0.90))),\n",
        "        (\"Medium (0.70-0.80)\", np.sum((confidences >= 0.70) & (confidences < 0.80))),\n",
        "        (\"Low (0.50-0.70)\", np.sum((confidences >= 0.50) & (confidences < 0.70))),\n",
        "        (\"Very Low (<0.50)\", np.sum(confidences < 0.50)),\n",
        "    ]\n",
        "\n",
        "    for range_name, count in conf_ranges:\n",
        "        percentage = (count / len(confidences)) * 100\n",
        "        print(f\"  {range_name:25s}: {count:4d} ({percentage:5.1f}%)\")\n",
        "\n",
        "    # Confidence by correctness\n",
        "    correct_mask = np.array([t == p for t, p in zip(true_labels, pred_labels)])\n",
        "    correct_confidences = confidences[correct_mask]\n",
        "    incorrect_confidences = confidences[~correct_mask]\n",
        "\n",
        "    print(\"\\nConfidence by Prediction Correctness:\")\n",
        "    print(f\"  Correct predictions:   Mean={np.mean(correct_confidences):.4f}, \"\n",
        "          f\"Median={np.median(correct_confidences):.4f}\")\n",
        "    if len(incorrect_confidences) > 0:\n",
        "        print(f\"  Incorrect predictions: Mean={np.mean(incorrect_confidences):.4f}, \"\n",
        "              f\"Median={np.median(incorrect_confidences):.4f}\")\n",
        "    else:\n",
        "        print(f\"  Incorrect predictions: None (Perfect accuracy!)\")\n",
        "\n",
        "    print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "    # ============================================================\n",
        "    # SAVE DETAILED RESULTS\n",
        "    # ============================================================\n",
        "    results_df = pd.DataFrame({\n",
        "        'raw_text': df_test[config.RAW_TEXT_COLUMN].tolist(),\n",
        "        'normalized_text': test_texts,\n",
        "        'true_intent': true_labels,\n",
        "        'predicted_intent': pred_labels,\n",
        "        'confidence': confidences,\n",
        "        'correct': correct_mask\n",
        "    })\n",
        "\n",
        "    # Add top-3 predictions for each sample\n",
        "    top3_intents = []\n",
        "    top3_probs = []\n",
        "\n",
        "    for probs in all_probs:\n",
        "        top3_idx = np.argsort(probs)[-3:][::-1]  # Top 3 indices\n",
        "        top3_intents.append([id2label[idx] for idx in top3_idx])\n",
        "        top3_probs.append(probs[top3_idx].tolist())\n",
        "\n",
        "    results_df['top3_intents'] = [str(intents) for intents in top3_intents]\n",
        "    results_df['top3_probabilities'] = [str(probs) for probs in top3_probs]\n",
        "\n",
        "    # Save results\n",
        "    results_path = f\"evaluation_results{report_suffix}.csv\"\n",
        "    results_df.to_csv(results_path, index=False, encoding='utf-8')\n",
        "    logging.info(f\"✓ Evaluation results saved to: {results_path}\")\n",
        "\n",
        "    # ============================================================\n",
        "    # ERROR ANALYSIS\n",
        "    # ============================================================\n",
        "    errors = results_df[results_df['correct'] == False].copy()\n",
        "\n",
        "    if len(errors) > 0:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"ERROR ANALYSIS\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"Total Errors: {len(errors)} ({len(errors)/len(results_df)*100:.2f}%)\")\n",
        "\n",
        "        # Error patterns\n",
        "        error_patterns = (\n",
        "            errors.groupby(['true_intent', 'predicted_intent'])\n",
        "            .size()\n",
        "            .sort_values(ascending=False)\n",
        "            .head(10)\n",
        "        )\n",
        "\n",
        "        print(\"\\nTop 10 Error Patterns:\")\n",
        "        print(\"-\" * 70)\n",
        "        for (true_int, pred_int), count in error_patterns.items():\n",
        "            percentage = (count / len(errors)) * 100\n",
        "            print(f\"  {true_int:40s} → {pred_int:40s}: {count:3d} ({percentage:4.1f}%)\")\n",
        "\n",
        "        # Low confidence errors\n",
        "        low_conf_errors = errors[errors['confidence'] < 0.5]\n",
        "        if len(low_conf_errors) > 0:\n",
        "            print(f\"\\nLow Confidence Errors (<0.5): {len(low_conf_errors)}\")\n",
        "            print(\"  (These are expected errors - model was uncertain)\")\n",
        "\n",
        "        # High confidence errors (more concerning)\n",
        "        high_conf_errors = errors[errors['confidence'] >= 0.8]\n",
        "        if len(high_conf_errors) > 0:\n",
        "            print(f\"\\n High Confidence Errors (≥0.8): {len(high_conf_errors)}\")\n",
        "            print(\"  (These are concerning - model was confident but wrong)\")\n",
        "            print(\"\\n  Top 5 High-Confidence Errors:\")\n",
        "            for idx, row in high_conf_errors.nlargest(5, 'confidence').iterrows():\n",
        "                print(f\"    Confidence: {row['confidence']:.3f}\")\n",
        "                print(f\"    Text: {row['normalized_text'][:80]}...\")\n",
        "                print(f\"    True: {row['true_intent']}\")\n",
        "                print(f\"    Predicted: {row['predicted_intent']}\")\n",
        "                print()\n",
        "\n",
        "        # Save error details\n",
        "        errors = errors.sort_values('confidence')\n",
        "        errors_path = f\"classification_errors{report_suffix}.csv\"\n",
        "        errors.to_csv(errors_path, index=False, encoding='utf-8')\n",
        "        logging.info(f\"✓ Error details saved to: {errors_path}\")\n",
        "\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"NO CLASSIFICATION ERRORS - PERFECT ACCURACY!\")\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "    # ============================================================\n",
        "    # CONFUSION MATRIX\n",
        "    # ============================================================\n",
        "    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=unique_labels,\n",
        "        yticklabels=unique_labels,\n",
        "        cbar_kws={'label': 'Count'}\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix (Accuracy: {test_acc:.3f}, F1: {test_f1:.3f})')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    os.makedirs(config.PLOT_SAVE_PATH, exist_ok=True)\n",
        "    cm_path = f\"{config.PLOT_SAVE_PATH}/confusion_matrix{report_suffix}.png\"\n",
        "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    logging.info(f\"Confusion matrix saved to: {cm_path}\")\n",
        "\n",
        "    # ============================================================\n",
        "    # CONFIDENCE HISTOGRAM\n",
        "    # ============================================================\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Overall confidence distribution\n",
        "    axes[0].hist(confidences, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "    axes[0].axvline(np.mean(confidences), color='red', linestyle='--',\n",
        "                    label=f'Mean: {np.mean(confidences):.3f}')\n",
        "    axes[0].axvline(np.median(confidences), color='green', linestyle='--',\n",
        "                    label=f'Median: {np.median(confidences):.3f}')\n",
        "    axes[0].set_xlabel('Confidence Score')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Overall Confidence Distribution')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # Confidence by correctness\n",
        "    if len(incorrect_confidences) > 0:\n",
        "        axes[1].hist(correct_confidences, bins=30, alpha=0.6, color='green',\n",
        "                     label=f'Correct (n={len(correct_confidences)})', edgecolor='black')\n",
        "        axes[1].hist(incorrect_confidences, bins=30, alpha=0.6, color='red',\n",
        "                     label=f'Incorrect (n={len(incorrect_confidences)})', edgecolor='black')\n",
        "    else:\n",
        "        axes[1].hist(correct_confidences, bins=30, alpha=0.7, color='green',\n",
        "                     label=f'All Correct (n={len(correct_confidences)})', edgecolor='black')\n",
        "\n",
        "    axes[1].set_xlabel('Confidence Score')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title('Confidence by Prediction Correctness')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    conf_path = f\"{config.PLOT_SAVE_PATH}/confidence_distribution{report_suffix}.png\"\n",
        "    plt.savefig(conf_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    logging.info(f\"Confidence distribution saved to: {conf_path}\")\n",
        "\n",
        "    return test_f1"
      ],
      "metadata": {
        "id": "4cP3K9Lxlhrb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensamble training and inference"
      ],
      "metadata": {
        "id": "9x9aqqtjaNmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ensemble_models(\n",
        "    config: Config,\n",
        "    df_trainval: pd.DataFrame,\n",
        "    label2id: Dict,\n",
        "    id2label: Dict,\n",
        "    num_labels: int,\n",
        "    text_column: str,\n",
        "    num_seeds: int = 5\n",
        ") -> List[str]:\n",
        "\n",
        "    saved_model_paths = []\n",
        "\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(f\"TRAINING ENSEMBLE ({num_seeds} seeds)\")\n",
        "    logging.info(\"=\" * 70)\n",
        "\n",
        "    # Base tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
        "\n",
        "    for i in range(num_seeds):\n",
        "        seed = 42 + i\n",
        "        current_suffix = f\"_seed_{seed}\"\n",
        "        logging.info(f\"--- Starting Training for Seed {seed} ---\")\n",
        "\n",
        "        # Different splits for each seed\n",
        "        train_df, val_df = train_test_split(\n",
        "            df_trainval,\n",
        "            test_size=0.1,\n",
        "            random_state=seed,\n",
        "            stratify=df_trainval['labels']\n",
        "        )\n",
        "\n",
        "        train_texts = train_df[text_column].tolist()\n",
        "        train_labels = train_df['labels'].tolist()\n",
        "        val_texts = val_df[text_column].tolist()\n",
        "        val_labels = val_df['labels'].tolist()\n",
        "\n",
        "        # Train with current seed\n",
        "        path = finetune_model(\n",
        "            config=config,\n",
        "            tokenizer=tokenizer,\n",
        "            train_texts=train_texts,\n",
        "            train_labels=train_labels,\n",
        "            val_texts=val_texts,\n",
        "            val_labels=val_labels,\n",
        "            label2id=label2id,\n",
        "            id2label=id2label,\n",
        "            num_labels=num_labels,\n",
        "            fold_id=f\"SEED_{seed}\",\n",
        "            save_model=True,\n",
        "            model_save_path=f\"{config.MODEL_SAVE_PATH}{current_suffix}\"\n",
        "        )\n",
        "\n",
        "        # Save config for current seed\n",
        "        config.save(f\"{config.MODEL_SAVE_PATH}{current_suffix}/training_config.json\")\n",
        "        saved_model_paths.append(f\"{config.MODEL_SAVE_PATH}{current_suffix}\")\n",
        "\n",
        "    return saved_model_paths"
      ],
      "metadata": {
        "id": "IZ-Wio7rHmhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleInferencePipeline:\n",
        "    def __init__(self, model_paths: List[str], device: str = None):\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.models = []\n",
        "\n",
        "        logging.info(f\"Loading {len(model_paths)} models for ensemble...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_paths[0])\n",
        "\n",
        "        # Load all models\n",
        "        for path in model_paths:\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(path)\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "            self.models.append(model)\n",
        "\n",
        "        self.config = self.models[0].config\n",
        "        logging.info(\"Ensemble loaded successfully.\")\n",
        "\n",
        "    def predict_batch(\n",
        "        self,\n",
        "        texts: List[str],\n",
        "        batch_size: int = 32,\n",
        "        temperature: float = 1.0,\n",
        "        threshold: float = 0.0,\n",
        "        return_confidences: bool = False\n",
        "    ):\n",
        "        all_preds_ids = []\n",
        "        all_confidences = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Ensemble Batch\"):\n",
        "            batch_texts = texts[i : i + batch_size]\n",
        "            inputs = self.tokenizer(\n",
        "                batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128\n",
        "            ).to(self.device)\n",
        "\n",
        "            # Clean inputs if needed\n",
        "            if \"token_type_ids\" in inputs: inputs.pop(\"token_type_ids\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits_list = []\n",
        "                for model in self.models:\n",
        "                    outputs = model(**inputs)\n",
        "                    logits_list.append(outputs.logits)\n",
        "\n",
        "                # Average (soft voting)\n",
        "                avg_logits = torch.stack(logits_list).mean(dim=0)\n",
        "\n",
        "                # Apply temperature and softmax on the average\n",
        "                scaled_logits = avg_logits / temperature\n",
        "                probs = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
        "\n",
        "                confidences, predictions = torch.max(probs, dim=-1)\n",
        "\n",
        "                all_preds_ids.extend(predictions.cpu().numpy())\n",
        "                all_confidences.extend(confidences.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        # Thresholding\n",
        "        predicted_labels = []\n",
        "        for idx, conf in zip(all_preds_ids, all_confidences):\n",
        "            if conf < threshold:\n",
        "                predicted_labels.append(\"NOMATCH\")\n",
        "            else:\n",
        "                predicted_labels.append(self.config.id2label[idx])\n",
        "\n",
        "        if return_confidences:\n",
        "            return predicted_labels, all_preds_ids, np.array(all_confidences), np.array(all_probs)\n",
        "        else:\n",
        "            return predicted_labels, all_preds_ids"
      ],
      "metadata": {
        "id": "bN4E8fXqHzMQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Learning"
      ],
      "metadata": {
        "id": "ETPxEtqUlEG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, InputExample, losses, models, evaluation\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_contrastive_embeddings(\n",
        "    config: Config,\n",
        "    df_train: pd.DataFrame,\n",
        "    text_col: str,\n",
        "    label_col: str,\n",
        "    output_path: str = \"contrastive_bert_base\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Stage 1: Fine-tune the BERT body using Contrastive Learning.\n",
        "    This aligns embeddings so that same-intents are close and diff-intents are far.\n",
        "    \"\"\"\n",
        "    logging.info(\"=\"*70)\n",
        "    logging.info(\"STAGE 1: CONTRASTIVE EMBEDDING TRAINING\")\n",
        "    logging.info(\"=\"*70)\n",
        "\n",
        "    # 1. Prepare Data for Contrastive Learning\n",
        "    # We create a list of InputExamples.\n",
        "    # For MultipleNegativesRankingLoss, we just need pairs of (Anchor, Positive).\n",
        "    # The loss function treats all other samples in the batch as Negatives (In-batch negatives).\n",
        "\n",
        "    train_examples = []\n",
        "\n",
        "    # Group by intent to create positive pairs\n",
        "    intent_groups = df_train.groupby(label_col)[text_col].apply(list).to_dict()\n",
        "\n",
        "    import random\n",
        "    random.seed(42)\n",
        "\n",
        "    # Generate pairs (Anchor, Positive)\n",
        "    # We want to maximize the number of pairs to give the model rich signal\n",
        "    for intent, texts in intent_groups.items():\n",
        "        if len(texts) < 2: continue\n",
        "\n",
        "        # Create pairs: (Text A, Text B) where both have same intent\n",
        "        # We can cycle through to create robust pairs\n",
        "        for i in range(len(texts)):\n",
        "            anchor = texts[i]\n",
        "            # Pick a random positive that isn't the anchor\n",
        "            # (Or pick multiple positives per anchor)\n",
        "            positive_idx = (i + 1) % len(texts)\n",
        "            positive = texts[positive_idx]\n",
        "\n",
        "            train_examples.append(InputExample(texts=[anchor, positive], label=1))\n",
        "\n",
        "            # Augmentation: Add another pair with a different positive to robustify\n",
        "            if len(texts) > 2:\n",
        "                pos_idx_2 = (i + 2) % len(texts)\n",
        "                train_examples.append(InputExample(texts=[anchor, texts[pos_idx_2]], label=1))\n",
        "\n",
        "    logging.info(f\"Generated {len(train_examples)} contrastive pairs.\")\n",
        "\n",
        "    # 2. Define Model Architecture for Sentence Transformers\n",
        "    # We wrap your specific Italian BERT model\n",
        "    word_embedding_model = models.Transformer(config.MODEL_NAME, max_seq_length=config.MAX_LEN)\n",
        "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "    # 3. Define DataLoader and Loss\n",
        "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=config.BATCH_SIZE)\n",
        "\n",
        "    # MultipleNegativesRankingLoss is incredible for this.\n",
        "    # It calculates loss: -log(exp(sim(a,p)) / sum(exp(sim(a, n))))\n",
        "    # Effectively maximizing sim(a,p) while minimizing sim(a, everything_else_in_batch)\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "    # 4. Train\n",
        "    # Usually 1-3 epochs is enough for contrastive fine-tuning\n",
        "    model.fit(\n",
        "        train_objectives=[(train_dataloader, train_loss)],\n",
        "        epochs=3, # Keep it short to avoid overfitting on the specifics\n",
        "        warmup_steps=int(len(train_dataloader) * 0.1),\n",
        "        show_progress_bar=True,\n",
        "        output_path=output_path\n",
        "    )\n",
        "\n",
        "    logging.info(f\"Contrastive Model saved to {output_path}\")\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "Znjlj5nvSzNW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, InputExample, losses, models, util\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_with_hard_negatives(\n",
        "    config: Config,\n",
        "    df_train: pd.DataFrame,\n",
        "    text_col: str,\n",
        "    label_col: str,\n",
        "    output_path: str = \"contrastive_bert_hard_negatives\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Advanced Embedding Training:\n",
        "    1. Trains a base model using MultipleNegativesRankingLoss (MNRL).\n",
        "    2. Uses that base model to MINE Hard Negatives (wrong intents that look similar).\n",
        "    3. Fine-tunes using TripletLoss to force those specific errors apart.\n",
        "    \"\"\"\n",
        "    logging.info(\"=\"*70)\n",
        "    logging.info(\"STARTING 2-STAGE CONTRASTIVE TRAINING WITH HARD NEGATIVES\")\n",
        "    logging.info(\"=\"*70)\n",
        "\n",
        "    # ==========================================\n",
        "    # STAGE 1: Warmup with MNRL (The Standard Approach)\n",
        "    # ==========================================\n",
        "    logging.info(\"--- Stage 1: Warmup with MultipleNegativesRankingLoss ---\")\n",
        "\n",
        "    # Define the Base Model\n",
        "    word_embedding_model = models.Transformer(config.MODEL_NAME, max_seq_length=config.MAX_LEN)\n",
        "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "    # Create simple pairs (Anchor, Positive)\n",
        "    train_examples_mnrl = []\n",
        "    intent_groups = df_train.groupby(label_col)[text_col].apply(list).to_dict()\n",
        "\n",
        "    for intent, texts in intent_groups.items():\n",
        "        if len(texts) < 2: continue\n",
        "        for i in range(len(texts)):\n",
        "            anchor = texts[i]\n",
        "            positive = texts[(i + 1) % len(texts)] # Simple cycle\n",
        "            train_examples_mnrl.append(InputExample(texts=[anchor, positive], label=1))\n",
        "\n",
        "    # Train Stage 1\n",
        "    train_dataloader_mnrl = DataLoader(train_examples_mnrl, shuffle=True, batch_size=config.BATCH_SIZE)\n",
        "    train_loss_mnrl = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "    model.fit(\n",
        "        train_objectives=[(train_dataloader_mnrl, train_loss_mnrl)],\n",
        "        epochs=1, # Just 1 epoch to get embeddings roughly aligned\n",
        "        warmup_steps=int(len(train_dataloader_mnrl) * 0.1),\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # ==========================================\n",
        "    # STAGE 2: Mining Hard Negatives\n",
        "    # ==========================================\n",
        "    logging.info(\"--- Stage 2: Mining Hard Negatives & Triplet Training ---\")\n",
        "    logging.info(\"Encoding all training data to find confusion points...\")\n",
        "\n",
        "    # 1. Encode all training texts to find similarities\n",
        "    # We need a list of all texts and their corresponding labels\n",
        "    all_texts = df_train[text_col].tolist()\n",
        "    all_labels = df_train[label_col].tolist()\n",
        "\n",
        "    # Encode everything (on GPU)\n",
        "    embeddings = model.encode(all_texts, convert_to_tensor=True, show_progress_bar=True)\n",
        "\n",
        "    # 2. Mine Triplets (Anchor, Positive, HARD Negative)\n",
        "    triplets = []\n",
        "\n",
        "    # Group indices by label for fast positive lookup\n",
        "    label_to_indices = df_train.groupby(label_col).indices\n",
        "\n",
        "    # Calculate Cosine Similarity Matrix for the whole dataset\n",
        "    # This might be heavy for >50k rows, but fine for <10k.\n",
        "    # If OOM, do this in batches.\n",
        "    cos_scores = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "    logging.info(\"Generating Triplets...\")\n",
        "\n",
        "    # For every sample in the dataset...\n",
        "    for idx, anchor_text in enumerate(tqdm(all_texts, desc=\"Mining\")):\n",
        "        anchor_label = all_labels[idx]\n",
        "\n",
        "        # A. Find a Positive (Same Label)\n",
        "        possible_positives = label_to_indices[anchor_label]\n",
        "        if len(possible_positives) < 2: continue\n",
        "\n",
        "        # Pick a random positive that isn't the anchor itself\n",
        "        pos_idx = random.choice(possible_positives)\n",
        "        while pos_idx == idx:\n",
        "            pos_idx = random.choice(possible_positives)\n",
        "        positive_text = all_texts[pos_idx]\n",
        "\n",
        "        # B. Find a HARD Negative (Different Label, but High Similarity)\n",
        "        # Get semantic scores for this anchor against EVERYONE else\n",
        "        scores = cos_scores[idx]\n",
        "\n",
        "        # Sort scores descending (Highest similarity first)\n",
        "        top_results = torch.topk(scores, k=20) # Look at top 20 closest sentences\n",
        "\n",
        "        hard_negative_text = None\n",
        "\n",
        "        for score, match_idx in zip(top_results.values, top_results.indices):\n",
        "            match_idx = match_idx.item()\n",
        "            # If the high-similarity match has a DIFFERENT label, it's a Hard Negative!\n",
        "            if all_labels[match_idx] != anchor_label:\n",
        "                hard_negative_text = all_texts[match_idx]\n",
        "                break # Found the hardest one, stop looking\n",
        "\n",
        "        # If we didn't find a hard negative in top 20, pick a semi-hard one random\n",
        "        if hard_negative_text is None:\n",
        "            # Fallback: Pick a random index from a different label\n",
        "            neg_idx = random.randint(0, len(all_texts)-1)\n",
        "            while all_labels[neg_idx] == anchor_label:\n",
        "                neg_idx = random.randint(0, len(all_texts)-1)\n",
        "            hard_negative_text = all_texts[neg_idx]\n",
        "\n",
        "        # Create Triplet\n",
        "        triplets.append(InputExample(texts=[anchor_text, positive_text, hard_negative_text]))\n",
        "\n",
        "    logging.info(f\"Mined {len(triplets)} triplets.\")\n",
        "\n",
        "    # ==========================================\n",
        "    # STAGE 3: Train with Triplet Loss\n",
        "    # ==========================================\n",
        "    train_dataloader_triplet = DataLoader(triplets, shuffle=True, batch_size=config.BATCH_SIZE)\n",
        "\n",
        "    # TripletLoss minimizes: dist(anchor, positive) - dist(anchor, negative) + margin\n",
        "    # FIX: The parameter is named 'triplet_margin'\n",
        "    train_loss_triplet = losses.TripletLoss(\n",
        "        model=model,\n",
        "        distance_metric=losses.TripletDistanceMetric.COSINE,\n",
        "        triplet_margin=0.5\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_objectives=[(train_dataloader_triplet, train_loss_triplet)],\n",
        "        epochs=2, # Fine-tune specifically on the hard cases\n",
        "        warmup_steps=int(len(train_dataloader_triplet) * 0.1),\n",
        "        show_progress_bar=True,\n",
        "        output_path=output_path\n",
        "    )\n",
        "\n",
        "    logging.info(f\"Hard Negative Model saved to {output_path}\")\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "9X0uEyd-3J-w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main executions"
      ],
      "metadata": {
        "id": "r4AndDu1lSW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Re-initialize Config to ensure defaults\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "config = Config()\n",
        "# Apply your optimized params (from your V2 code)\n",
        "config.LEARNING_RATE = 4.755892715970439e-05\n",
        "config.BATCH_SIZE = 24\n",
        "config.WEIGHT_DECAY = 0.000175\n",
        "config.WARMUP_RATIO = 0.000175\n",
        "config.ALPHA = 0.776\n",
        "config.FOCAL_GAMMA = 1.38\n",
        "config.LABEL_SMOOTHING = 0.092\n",
        "\n",
        "# 2. Reload Data\n",
        "train_df, test_df, l2id, id2l, n_labels = load_and_prep_data(config)\n",
        "\n",
        "contrastive_model_path = \"contrastive_bert\"\n",
        "\n",
        "if not os.path.exists(contrastive_model_path):\n",
        "    train_contrastive_embeddings(\n",
        "        config,\n",
        "        train_df,\n",
        "        config.RAW_TEXT_COLUMN,\n",
        "        config.LABEL_COLUMN,\n",
        "        output_path=contrastive_model_path\n",
        "    )\n",
        "\n",
        "# Point the Config to use the NEW contrastive model instead of the base 'dbmdz/bert...'\n",
        "logging.info(f\"Switching backbone to Contrastive Tuned Model: {contrastive_model_path}\")\n",
        "config.MODEL_NAME = contrastive_model_path  # <--- CRITICAL CHANGE\n",
        "\n",
        "# 3. Train\n",
        "# Ensure the model_save_suffix is unique to avoid overwriting issues\n",
        "model_path = train_final_model(\n",
        "    config,\n",
        "    train_df,\n",
        "    l2id,\n",
        "    id2l,\n",
        "    n_labels,\n",
        "    config.RAW_TEXT_COLUMN,\n",
        "    #model_save_suffix=\"_final_v3\"  # NEW NAME\n",
        ")\n",
        "\n",
        "# 4. Evaluate\n",
        "# This should now work without any \"token_type_id\" errors\n",
        "evaluate_on_test_set(\n",
        "    config,\n",
        "    test_df,\n",
        "    model_path,\n",
        "    l2id,\n",
        "    id2l,\n",
        "    n_labels,\n",
        "    config.RAW_TEXT_COLUMN,\n",
        "    report_suffix=\"_final_v3\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lKSrUKdgvaMf",
        "outputId": "d60e59ce-5394-4b11-d1e6-a9360740648d",
        "collapsed": true
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "LOADING DATASET\n",
            "======================================================================\n",
            "Loaded 3990 samples\n",
            "Model will train on 11 valid intents.\n",
            "\n",
            "11 intents found:\n",
            "  Ordini.Richiesta_Stato_Consegna                    :  759 (19.02%)\n",
            "  ComingSoon.Contabilità.Informazioni                :  619 (15.51%)\n",
            "  ComingSoon.Procedure.Ordini_Informazioni           :  494 (12.38%)\n",
            "  Generico.Richiesta_Generica                        :  420 (10.53%)\n",
            "  Problemi.Lettura_Device                            :  380 ( 9.52%)\n",
            "  Problemi.Alimentazione_Device                      :  361 ( 9.05%)\n",
            "  ComingSoon.Problemi.Autenticazione_Smarrimento_Blo :  279 ( 6.99%)\n",
            "  Problemi.Software_Device                           :  225 ( 5.64%)\n",
            "  Procedure.Accettazione_Materiale_Problemi          :  224 ( 5.61%)\n",
            "  NOMATCH                                            :  137 ( 3.43%)\n",
            "\n",
            "Train/Val: 3391 | Test: 599\n",
            "Switching backbone to Contrastive Tuned Model: contrastive_bert\n",
            "======================================================================\n",
            "TRAINING FINAL MODEL\n",
            "======================================================================\n",
            "Using optimized hyperparameters:\n",
            "  LR=4.76e-05, BS=24, WD=0.000\n",
            "Training Fold FINAL...\n",
            "Class balance weights: 0.500 - 2.000\n",
            "Final weights: 0.549 - 2.195\n",
            "Using Focal Loss (γ=1.38, smoothing=0.092)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1664' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1664/1920 02:28 < 00:22, 11.18 it/s, Epoch 13/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.239380</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>0.895343</td>\n",
              "      <td>0.885977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.174600</td>\n",
              "      <td>0.218332</td>\n",
              "      <td>0.879412</td>\n",
              "      <td>0.880932</td>\n",
              "      <td>0.861607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.096300</td>\n",
              "      <td>0.272664</td>\n",
              "      <td>0.902941</td>\n",
              "      <td>0.901128</td>\n",
              "      <td>0.879421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.078300</td>\n",
              "      <td>0.326748</td>\n",
              "      <td>0.879412</td>\n",
              "      <td>0.876826</td>\n",
              "      <td>0.858737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.413297</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.870738</td>\n",
              "      <td>0.842096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>0.373174</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>0.892581</td>\n",
              "      <td>0.863233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>0.442378</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.887060</td>\n",
              "      <td>0.862104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>0.421826</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.883013</td>\n",
              "      <td>0.862160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.440482</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.887155</td>\n",
              "      <td>0.864609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.431495</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.880895</td>\n",
              "      <td>0.853240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.430148</td>\n",
              "      <td>0.885294</td>\n",
              "      <td>0.885492</td>\n",
              "      <td>0.862498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.467122</td>\n",
              "      <td>0.891176</td>\n",
              "      <td>0.891031</td>\n",
              "      <td>0.864158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.467318</td>\n",
              "      <td>0.888235</td>\n",
              "      <td>0.887705</td>\n",
              "      <td>0.861669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold FINAL: Best F1 = 0.9011\n",
            "Model saved to italian_intent_model\n",
            "Final model training complete. Val F1: 0.9011\n",
            "Model saved to: italian_intent_model\n",
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION ON TEST SET\n",
            "======================================================================\n",
            "Loading inference model from italian_intent_model to cuda...\n",
            "Model loaded successfully.\n",
            "Running inference on 599 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Batch: 100%|██████████| 25/25 [00:00<00:00, 41.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8898\n",
            "Test F1 Score: 0.8890\n",
            "\n",
            "======================================================================\n",
            "DETAILED CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "                                                             precision    recall  f1-score   support\n",
            "\n",
            "                        ComingSoon.Contabilità.Informazioni       0.96      0.98      0.97        93\n",
            "ComingSoon.Problemi.Autenticazione_Smarrimento_Blocco_Carta       0.95      0.86      0.90        42\n",
            "                   ComingSoon.Procedure.Ordini_Informazioni       0.80      0.80      0.80        74\n",
            "                                Generico.Richiesta_Generica       0.83      0.78      0.80        63\n",
            "                                                    NOMATCH       0.94      0.75      0.83        20\n",
            "                            Ordini.Richiesta_Stato_Consegna       0.87      0.85      0.86       114\n",
            "                              Problemi.Alimentazione_Device       1.00      0.98      0.99        54\n",
            "                                    Problemi.Lettura_Device       0.92      0.98      0.95        57\n",
            "                                   Problemi.Software_Device       0.85      1.00      0.92        34\n",
            "                      Procedure.Accettazione_Materiale_Info       0.93      0.93      0.93        14\n",
            "                  Procedure.Accettazione_Materiale_Problemi       0.81      0.88      0.85        34\n",
            "\n",
            "                                                   accuracy                           0.89       599\n",
            "                                                  macro avg       0.89      0.89      0.89       599\n",
            "                                               weighted avg       0.89      0.89      0.89       599\n",
            "\n",
            "\n",
            "======================================================================\n",
            "CONFIDENCE STATISTICS\n",
            "======================================================================\n",
            "Mean Confidence:   0.9817\n",
            "Median Confidence: 0.9995\n",
            "Std Confidence:    0.0774\n",
            "Min Confidence:    0.3515\n",
            "Max Confidence:    0.9997\n",
            "\n",
            "Confidence Distribution:\n",
            "  Very High (>0.90)        :  569 ( 95.0%)\n",
            "  High (0.80-0.90)         :    8 (  1.3%)\n",
            "  Medium (0.70-0.80)       :    7 (  1.2%)\n",
            "  Low (0.50-0.70)          :   13 (  2.2%)\n",
            "  Very Low (<0.50)         :    2 (  0.3%)\n",
            "\n",
            "Confidence by Prediction Correctness:\n",
            "  Correct predictions:   Mean=0.9876, Median=0.9995\n",
            "  Incorrect predictions: Mean=0.9345, Median=0.9951\n",
            "======================================================================\n",
            "\n",
            "✓ Evaluation results saved to: evaluation_results_final_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ERROR ANALYSIS\n",
            "======================================================================\n",
            "Total Errors: 66 (11.02%)\n",
            "\n",
            "Top 10 Error Patterns:\n",
            "----------------------------------------------------------------------\n",
            "  Ordini.Richiesta_Stato_Consegna          → ComingSoon.Procedure.Ordini_Informazioni:  13 (19.7%)\n",
            "  ComingSoon.Procedure.Ordini_Informazioni → Ordini.Richiesta_Stato_Consegna         :   9 (13.6%)\n",
            "  ComingSoon.Procedure.Ordini_Informazioni → Procedure.Accettazione_Materiale_Problemi:   4 ( 6.1%)\n",
            "  ComingSoon.Problemi.Autenticazione_Smarrimento_Blocco_Carta → Problemi.Software_Device                :   4 ( 6.1%)\n",
            "  NOMATCH                                  → Generico.Richiesta_Generica             :   4 ( 6.1%)\n",
            "  Ordini.Richiesta_Stato_Consegna          → Generico.Richiesta_Generica             :   4 ( 6.1%)\n",
            "  Generico.Richiesta_Generica              → Ordini.Richiesta_Stato_Consegna         :   4 ( 6.1%)\n",
            "  Generico.Richiesta_Generica              → Problemi.Lettura_Device                 :   3 ( 4.5%)\n",
            "  Generico.Richiesta_Generica              → Procedure.Accettazione_Materiale_Problemi:   3 ( 4.5%)\n",
            "  ComingSoon.Contabilità.Informazioni      → Ordini.Richiesta_Stato_Consegna         :   2 ( 3.0%)\n",
            "\n",
            " High Confidence Errors (≥0.8): 57\n",
            "  (These are concerning - model was confident but wrong)\n",
            "\n",
            "  Top 5 High-Confidence Errors:\n",
            "    Confidence: 1.000\n",
            "    Text: mi serve assistenza per un pagamento...\n",
            "    True: Generico.Richiesta_Generica\n",
            "    Predicted: ComingSoon.Contabilità.Informazioni\n",
            "\n",
            "    Confidence: 1.000\n",
            "    Text: non capisco niente qua...\n",
            "    True: NOMATCH\n",
            "    Predicted: Generico.Richiesta_Generica\n",
            "\n",
            "    Confidence: 1.000\n",
            "    Text: Inna eh fine mese 8...\n",
            "    True: NOMATCH\n",
            "    Predicted: ComingSoon.Contabilità.Informazioni\n",
            "\n",
            "    Confidence: 1.000\n",
            "    Text: mi funziona il per scaricare i Gratta e Vinci cosa devo fare...\n",
            "    True: Procedure.Accettazione_Materiale_Info\n",
            "    Predicted: Problemi.Lettura_Device\n",
            "\n",
            "    Confidence: 0.999\n",
            "    Text: Ciao Mah guarda eh allora giacenza Lotto...\n",
            "    True: ComingSoon.Contabilità.Informazioni\n",
            "    Predicted: Ordini.Richiesta_Stato_Consegna\n",
            "\n",
            "✓ Error details saved to: classification_errors_final_v3.csv\n",
            "======================================================================\n",
            "\n",
            "Confusion matrix saved to: training_plots/confusion_matrix_final_v3.png\n",
            "Confidence distribution saved to: training_plots/confidence_distribution_final_v3.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.889042079540029"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.TEMPERATURE = 1\n",
        "config.CONFIDENCE_THRESHOLD = 0\n",
        "evaluate_on_test_set(\n",
        "    config,\n",
        "    test_df,\n",
        "    model_path,\n",
        "    l2id,\n",
        "    id2l,\n",
        "    n_labels,\n",
        "    config.RAW_TEXT_COLUMN,\n",
        "    report_suffix=\"_final_v3\"\n",
        ")"
      ],
      "metadata": {
        "id": "0t7Woajov01n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbce520-bffe-4d84-df23-3b523439074e",
        "collapsed": true
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL EVALUATION ON TEST SET\n",
            "======================================================================\n",
            "Loading inference model from italian_intent_model to cuda...\n",
            "Model loaded successfully.\n",
            "Running inference on 599 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Batch: 100%|██████████| 25/25 [00:00<00:00, 41.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8865\n",
            "Test F1 Score: 0.8852\n",
            "\n",
            "======================================================================\n",
            "DETAILED CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "                                                             precision    recall  f1-score   support\n",
            "\n",
            "                        ComingSoon.Contabilità.Informazioni       0.96      0.98      0.97        93\n",
            "ComingSoon.Problemi.Autenticazione_Smarrimento_Blocco_Carta       0.92      0.86      0.89        42\n",
            "                   ComingSoon.Procedure.Ordini_Informazioni       0.80      0.80      0.80        74\n",
            "                                Generico.Richiesta_Generica       0.83      0.78      0.80        63\n",
            "                                                    NOMATCH       0.93      0.65      0.76        20\n",
            "                            Ordini.Richiesta_Stato_Consegna       0.87      0.85      0.86       114\n",
            "                              Problemi.Alimentazione_Device       1.00      0.98      0.99        54\n",
            "                                    Problemi.Lettura_Device       0.92      0.98      0.95        57\n",
            "                                   Problemi.Software_Device       0.85      1.00      0.92        34\n",
            "                      Procedure.Accettazione_Materiale_Info       0.87      0.93      0.90        14\n",
            "                  Procedure.Accettazione_Materiale_Problemi       0.81      0.88      0.85        34\n",
            "\n",
            "                                                   accuracy                           0.89       599\n",
            "                                                  macro avg       0.89      0.88      0.88       599\n",
            "                                               weighted avg       0.89      0.89      0.89       599\n",
            "\n",
            "\n",
            "======================================================================\n",
            "CONFIDENCE STATISTICS\n",
            "======================================================================\n",
            "Mean Confidence:   0.9743\n",
            "Median Confidence: 0.9963\n",
            "Std Confidence:    0.0856\n",
            "Min Confidence:    0.3300\n",
            "Max Confidence:    0.9978\n",
            "\n",
            "Confidence Distribution:\n",
            "  Very High (>0.90)        :  564 ( 94.2%)\n",
            "  High (0.80-0.90)         :    9 (  1.5%)\n",
            "  Medium (0.70-0.80)       :    6 (  1.0%)\n",
            "  Low (0.50-0.70)          :   17 (  2.8%)\n",
            "  Very Low (<0.50)         :    3 (  0.5%)\n",
            "\n",
            "Confidence by Prediction Correctness:\n",
            "  Correct predictions:   Mean=0.9841, Median=0.9964\n",
            "  Incorrect predictions: Mean=0.8972, Median=0.9810\n",
            "======================================================================\n",
            "\n",
            "✓ Evaluation results saved to: evaluation_results_final_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ERROR ANALYSIS\n",
            "======================================================================\n",
            "Total Errors: 68 (11.35%)\n",
            "\n",
            "Top 10 Error Patterns:\n",
            "----------------------------------------------------------------------\n",
            "  Ordini.Richiesta_Stato_Consegna          → ComingSoon.Procedure.Ordini_Informazioni:  13 (19.1%)\n",
            "  ComingSoon.Procedure.Ordini_Informazioni → Ordini.Richiesta_Stato_Consegna         :   9 (13.2%)\n",
            "  ComingSoon.Procedure.Ordini_Informazioni → Procedure.Accettazione_Materiale_Problemi:   4 ( 5.9%)\n",
            "  Ordini.Richiesta_Stato_Consegna          → Generico.Richiesta_Generica             :   4 ( 5.9%)\n",
            "  Generico.Richiesta_Generica              → Ordini.Richiesta_Stato_Consegna         :   4 ( 5.9%)\n",
            "  ComingSoon.Problemi.Autenticazione_Smarrimento_Blocco_Carta → Problemi.Software_Device                :   4 ( 5.9%)\n",
            "  NOMATCH                                  → Generico.Richiesta_Generica             :   4 ( 5.9%)\n",
            "  Generico.Richiesta_Generica              → Procedure.Accettazione_Materiale_Problemi:   3 ( 4.4%)\n",
            "  Generico.Richiesta_Generica              → Problemi.Lettura_Device                 :   3 ( 4.4%)\n",
            "  ComingSoon.Contabilità.Informazioni      → Ordini.Richiesta_Stato_Consegna         :   2 ( 2.9%)\n",
            "\n",
            "Low Confidence Errors (<0.5): 3\n",
            "  (These are expected errors - model was uncertain)\n",
            "\n",
            " High Confidence Errors (≥0.8): 56\n",
            "  (These are concerning - model was confident but wrong)\n",
            "\n",
            "  Top 5 High-Confidence Errors:\n",
            "    Confidence: 0.997\n",
            "    Text: mi serve assistenza per un pagamento...\n",
            "    True: Generico.Richiesta_Generica\n",
            "    Predicted: ComingSoon.Contabilità.Informazioni\n",
            "\n",
            "    Confidence: 0.997\n",
            "    Text: non capisco niente qua...\n",
            "    True: NOMATCH\n",
            "    Predicted: Generico.Richiesta_Generica\n",
            "\n",
            "    Confidence: 0.997\n",
            "    Text: Inna eh fine mese 8...\n",
            "    True: NOMATCH\n",
            "    Predicted: ComingSoon.Contabilità.Informazioni\n",
            "\n",
            "    Confidence: 0.997\n",
            "    Text: mi funziona il per scaricare i Gratta e Vinci cosa devo fare...\n",
            "    True: Procedure.Accettazione_Materiale_Info\n",
            "    Predicted: Problemi.Lettura_Device\n",
            "\n",
            "    Confidence: 0.996\n",
            "    Text: Ciao Mah guarda eh allora giacenza Lotto...\n",
            "    True: ComingSoon.Contabilità.Informazioni\n",
            "    Predicted: Ordini.Richiesta_Stato_Consegna\n",
            "\n",
            "✓ Error details saved to: classification_errors_final_v3.csv\n",
            "======================================================================\n",
            "\n",
            "Confusion matrix saved to: training_plots/confusion_matrix_final_v3.png\n",
            "Confidence distribution saved to: training_plots/confidence_distribution_final_v3.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8852232288750148"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# POST-TRAINING CONFIDENCE CALIBRATION\n",
        "# =====================================================================\n",
        "# This is a SIMPLE approach that you can apply to your EXISTING model\n",
        "# without retraining from scratch.\n",
        "# =====================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "class TemperatureScaling:\n",
        "    \"\"\"\n",
        "    Simple temperature scaling for calibration.\n",
        "    Based on \"On Calibration of Modern Neural Networks\" (Guo et al., 2017)\n",
        "\n",
        "    This is a single learned parameter that scales all logits.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.temperature = 1.0\n",
        "\n",
        "    def fit(self, logits: np.ndarray, labels: np.ndarray):\n",
        "        \"\"\"\n",
        "        Find optimal temperature on validation set\n",
        "\n",
        "        Args:\n",
        "            logits: Raw model outputs [N, num_classes]\n",
        "            labels: True labels [N]\n",
        "        \"\"\"\n",
        "\n",
        "        def objective(temp):\n",
        "            \"\"\"Minimize negative log likelihood\"\"\"\n",
        "            scaled_logits = logits / temp[0]\n",
        "            # Compute softmax\n",
        "            exp_logits = np.exp(scaled_logits - np.max(scaled_logits, axis=1, keepdims=True))\n",
        "            probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "            # Compute cross-entropy\n",
        "            loss = log_loss(labels, probs)\n",
        "            return loss\n",
        "\n",
        "        # Optimize temperature\n",
        "        result = minimize(\n",
        "            objective,\n",
        "            x0=[1.0],  # Start at 1.0 (no scaling)\n",
        "            bounds=[(0.1, 10.0)],  # Temperature between 0.1 and 10\n",
        "            method='L-BFGS-B'\n",
        "        )\n",
        "\n",
        "        self.temperature = result.x[0]\n",
        "        print(f\"Optimal temperature: {self.temperature:.3f}\")\n",
        "\n",
        "        # Higher temperature (>1) = less confident\n",
        "        # Lower temperature (<1) = more confident\n",
        "        if self.temperature > 1.5:\n",
        "            print(\"⚠️  Model is OVERCONFIDENT - temperature scaling will help\")\n",
        "        elif self.temperature < 0.8:\n",
        "            print(\"⚠️  Model is UNDERCONFIDENT - might be undertrained\")\n",
        "        else:\n",
        "            print(\"✓ Model confidence is reasonable\")\n",
        "\n",
        "    def apply(self, logits: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply temperature scaling to logits\"\"\"\n",
        "        scaled_logits = logits / self.temperature\n",
        "        exp_logits = np.exp(scaled_logits - np.max(scaled_logits, axis=1, keepdims=True))\n",
        "        probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "        return probs\n",
        "\n",
        "\n",
        "def calibrate_existing_model(\n",
        "    model_path: str,\n",
        "    val_texts: List[str],\n",
        "    val_labels: List[int],\n",
        "    config: Config\n",
        ") -> TemperatureScaling:\n",
        "    \"\"\"\n",
        "    Calibrate an existing trained model using validation set\n",
        "\n",
        "    Returns:\n",
        "        calibrator: TemperatureScaling object to use in inference\n",
        "    \"\"\"\n",
        "\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(\"CALIBRATING MODEL CONFIDENCE\")\n",
        "    logging.info(\"=\" * 70)\n",
        "\n",
        "    # Load model\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Get logits on validation set\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    batch_size = 32\n",
        "    for i in tqdm(range(0, len(val_texts), batch_size), desc=\"Collecting logits\"):\n",
        "        batch_texts = val_texts[i:i + batch_size]\n",
        "        batch_labels = val_labels[i:i + batch_size]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            all_logits.append(logits.cpu().numpy())\n",
        "            all_labels.extend(batch_labels)\n",
        "\n",
        "    all_logits = np.vstack(all_logits)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Fit temperature scaling\n",
        "    calibrator = TemperatureScaling()\n",
        "    calibrator.fit(all_logits, all_labels)\n",
        "\n",
        "    # Compare before/after\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"CALIBRATION COMPARISON\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Before calibration\n",
        "    before_probs = torch.nn.functional.softmax(torch.tensor(all_logits), dim=-1).numpy()\n",
        "    before_conf = np.max(before_probs, axis=1)\n",
        "    before_preds = np.argmax(before_probs, axis=1)\n",
        "    before_acc = (before_preds == all_labels).mean()\n",
        "\n",
        "    # After calibration\n",
        "    after_probs = calibrator.apply(all_logits)\n",
        "    after_conf = np.max(after_probs, axis=1)\n",
        "    after_preds = np.argmax(after_probs, axis=1)\n",
        "    after_acc = (after_preds == all_labels).mean()\n",
        "\n",
        "    print(f\"Before Calibration:\")\n",
        "    print(f\"  Accuracy: {before_acc:.4f}\")\n",
        "    print(f\"  Mean Confidence: {before_conf.mean():.4f}\")\n",
        "    print(f\"  Median Confidence: {np.median(before_conf):.4f}\")\n",
        "\n",
        "    print(f\"\\nAfter Calibration:\")\n",
        "    print(f\"  Accuracy: {after_acc:.4f}\")\n",
        "    print(f\"  Mean Confidence: {after_conf.mean():.4f}\")\n",
        "    print(f\"  Median Confidence: {np.median(after_conf):.4f}\")\n",
        "\n",
        "    # Save calibrator\n",
        "    import pickle\n",
        "    with open(f\"{model_path}/temperature_calibrator.pkl\", 'wb') as f:\n",
        "        pickle.dump(calibrator, f)\n",
        "\n",
        "    logging.info(f\"✓ Calibrator saved to {model_path}/temperature_calibrator.pkl\")\n",
        "\n",
        "    return calibrator\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# MODIFIED INFERENCE PIPELINE WITH CALIBRATION\n",
        "# =====================================================================\n",
        "\n",
        "class CalibratedInferencePipeline:\n",
        "    \"\"\"\n",
        "    Enhanced inference with temperature scaling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path: str,\n",
        "        use_calibration: bool = True,\n",
        "        device: str = None\n",
        "    ):\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model_path = model_path\n",
        "\n",
        "        # Load model\n",
        "        from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Load calibrator if available\n",
        "        self.calibrator = None\n",
        "        if use_calibration:\n",
        "            calibrator_path = f\"{model_path}/temperature_calibrator.pkl\"\n",
        "            if os.path.exists(calibrator_path):\n",
        "                import pickle\n",
        "                with open(calibrator_path, 'rb') as f:\n",
        "                    self.calibrator = pickle.load(f)\n",
        "                logging.info(f\"✓ Loaded calibrator (T={self.calibrator.temperature:.3f})\")\n",
        "            else:\n",
        "                logging.warning(f\"⚠️  No calibrator found at {calibrator_path}\")\n",
        "\n",
        "    def predict_batch(\n",
        "        self,\n",
        "        texts: List[str],\n",
        "        batch_size: int = 32,\n",
        "        threshold: float = 0.7,\n",
        "        return_confidences: bool = False\n",
        "    ):\n",
        "        \"\"\"Inference with optional calibration\"\"\"\n",
        "\n",
        "        all_preds_ids = []\n",
        "        all_confidences = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Inference\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                batch_texts,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128\n",
        "            ).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                # Apply calibration if available\n",
        "                if self.calibrator is not None:\n",
        "                    probs = self.calibrator.apply(logits.cpu().numpy())\n",
        "                    probs = torch.tensor(probs)\n",
        "                else:\n",
        "                    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "                confidences, predictions = torch.max(probs, dim=-1)\n",
        "\n",
        "                all_preds_ids.extend(predictions.cpu().numpy())\n",
        "                all_confidences.extend(confidences.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        # Apply threshold\n",
        "        predicted_labels = []\n",
        "        for idx, conf in zip(all_preds_ids, all_confidences):\n",
        "            if conf < threshold:\n",
        "                predicted_labels.append(\"NOMATCH\")\n",
        "            else:\n",
        "                predicted_labels.append(self.model.config.id2label[idx])\n",
        "\n",
        "        if return_confidences:\n",
        "            return predicted_labels, all_preds_ids, np.array(all_confidences), np.array(all_probs)\n",
        "        else:\n",
        "            return predicted_labels, all_preds_ids\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# INTEGRATION: HOW TO USE\n",
        "# =====================================================================\n",
        "\n",
        "def calibrate_and_evaluate(config: Config, model_path: str, train_df, test_df, l2id, id2l, n_labels):\n",
        "    \"\"\"\n",
        "    Complete workflow: Calibrate → Evaluate\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Create calibration set (use 20% of training data)\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    _, cal_df = train_test_split(\n",
        "        train_df,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=train_df['labels']\n",
        "    )\n",
        "\n",
        "    cal_texts = cal_df[config.RAW_TEXT_COLUMN].tolist()\n",
        "    cal_labels = cal_df['labels'].tolist()\n",
        "\n",
        "    # Step 2: Calibrate model\n",
        "    calibrator = calibrate_existing_model(\n",
        "        model_path=model_path,\n",
        "        val_texts=cal_texts,\n",
        "        val_labels=cal_labels,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    # Step 3: Evaluate with calibration\n",
        "    pipeline = CalibratedInferencePipeline(\n",
        "        model_path=model_path,\n",
        "        use_calibration=True\n",
        "    )\n",
        "\n",
        "    test_texts = test_df[config.RAW_TEXT_COLUMN].tolist()\n",
        "    true_labels = test_df[config.LABEL_COLUMN].tolist()\n",
        "\n",
        "    pred_labels, pred_ids, confidences, all_probs = pipeline.predict_batch(\n",
        "        test_texts,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        threshold=config.CONFIDENCE_THRESHOLD,\n",
        "        return_confidences=True\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    from sklearn.metrics import accuracy_score, f1_score\n",
        "    test_acc = accuracy_score(true_labels, pred_labels)\n",
        "    test_f1 = f1_score(true_labels, pred_labels, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"CALIBRATED MODEL RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "    print(f\"Mean Confidence: {np.mean(confidences):.4f}\")\n",
        "    print(f\"Max Confidence: {np.max(confidences):.4f}\")\n",
        "    print(f\"# of 1.000 confidence predictions: {np.sum(confidences >= 0.9999)}\")\n",
        "\n",
        "    return test_f1\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# USAGE IN YOUR MAIN CODE\n",
        "# =====================================================================\n",
        "\n",
        "\"\"\"\n",
        "# After training your model:\n",
        "model_path = train_final_model(...)\n",
        "\n",
        "# Calibrate and evaluate:\n",
        "final_f1 = calibrate_and_evaluate(\n",
        "    config=config,\n",
        "    model_path=model_path,\n",
        "    train_df=train_df,\n",
        "    test_df=test_df,\n",
        "    l2id=l2id,\n",
        "    id2l=id2l,\n",
        "    n_labels=n_labels\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2V5tWmlVq9p5",
        "outputId": "7d04892d-224c-4d6b-c30f-328afcc2417d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# After training your model:\\nmodel_path = train_final_model(...)\\n\\n# Calibrate and evaluate:\\nfinal_f1 = calibrate_and_evaluate(\\n    config=config,\\n    model_path=model_path,\\n    train_df=train_df,\\n    test_df=test_df,\\n    l2id=l2id,\\n    id2l=id2l,\\n    n_labels=n_labels\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_f1 = calibrate_and_evaluate(\n",
        "    config=config,\n",
        "    model_path=model_path,\n",
        "    train_df=train_df,\n",
        "    test_df=test_df,\n",
        "    l2id=l2id,\n",
        "    id2l=id2l,\n",
        "    n_labels=n_labels\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPPUNS-xrKeq",
        "outputId": "3c02e2cc-eb10-408b-edca-213634633d15"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CALIBRATING MODEL CONFIDENCE\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting logits: 100%|██████████| 22/22 [00:00<00:00, 26.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal temperature: 1.394\n",
            "✓ Model confidence is reasonable\n",
            "\n",
            "======================================================================\n",
            "CALIBRATION COMPARISON\n",
            "======================================================================\n",
            "Before Calibration:\n",
            "  Accuracy: 0.9249\n",
            "  Mean Confidence: 0.9768\n",
            "  Median Confidence: 0.9962\n",
            "\n",
            "After Calibration:\n",
            "  Accuracy: 0.9249\n",
            "  Mean Confidence: 0.9397\n",
            "  Median Confidence: 0.9662\n",
            "✓ Calibrator saved to italian_intent_model/temperature_calibrator.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded calibrator (T=1.394)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|██████████| 25/25 [00:00<00:00, 40.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "CALIBRATED MODEL RESULTS\n",
            "======================================================================\n",
            "Test Accuracy: 0.8815\n",
            "Test F1 Score: 0.8806\n",
            "Mean Confidence: 0.9326\n",
            "Max Confidence: 0.9748\n",
            "# of 1.000 confidence predictions: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import deepcopy\n",
        "# ===================== MAIN EXECUTION =====================\n",
        "def main():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "\n",
        "    # Initialize configuration\n",
        "    config = Config()\n",
        "\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(\"BERT INTENT CLASSIFICATION PIPELINE\")\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(f\"Model: {config.MODEL_NAME}\")\n",
        "    logging.info(f\"Features enabled:\")\n",
        "    logging.info(f\"  - Focal Loss: {config.USE_FOCAL_LOSS}\")\n",
        "    logging.info(f\"  - Class Weights: {config.USE_CLASS_WEIGHTS}\")\n",
        "    logging.info(f\"  - Priority Scores: {config.USE_PRIORITY_SCORES}\")\n",
        "    logging.info(f\"  - Label Smoothing: {config.USE_LABEL_SMOOTHING}\")\n",
        "    logging.info(f\"  - Mixed Precision: {config.USE_MIXED_PRECISION}\")\n",
        "    logging.info(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "    # Load data\n",
        "    train_df, test_df, l2id, id2l, n_labels = load_and_prep_data(config)\n",
        "    text_column = config.RAW_TEXT_COLUMN\n",
        "\n",
        "    # Hyperparameter optimization\n",
        "    logging.info(\"Starting hyperparameter optimization...\")\n",
        "    # best_config, trials_df = run_hp_search_optuna(\n",
        "    #     config, train_df, l2id, id2l, n_labels, text_column\n",
        "    # )\n",
        "\n",
        "    best_config = copy.deepcopy(config)\n",
        "    best_config.LEARNING_RATE = 4.755892715970439e-05\n",
        "    best_config.BATCH_SIZE = 24\n",
        "    best_config.WEIGHT_DECAY = 0.0001751018975372498\n",
        "    best_config.WARMUP_RATIO = 0.0001751018975372498\n",
        "    best_config.ALPHA = 0.7768600075165988\n",
        "    best_config.FOCAL_GAMMA = 1.3798296530795757\n",
        "    best_config.LABEL_SMOOTHING = 0.09242568547841506\n",
        "\n",
        "    # Train final model\n",
        "    logging.info(\"Training final model with best hyperparameters...\")\n",
        "    model_path = train_final_model(\n",
        "        best_config, train_df, l2id, id2l, n_labels, text_column, \"_optimized2\"\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    logging.info(\"Evaluating on test set...\")\n",
        "    final_f1 = evaluate_on_test_set(\n",
        "        best_config, test_df, model_path, l2id, id2l, n_labels, text_column, \"_optimized2\"\n",
        "    )\n",
        "\n",
        "    # Final summary\n",
        "    logging.info(\"\\n\" + \"=\" * 70)\n",
        "    logging.info(\"TRAINING COMPLETE\")\n",
        "    logging.info(\"=\" * 70)\n",
        "    logging.info(f\"Final Test F1: {final_f1:.4f}\")\n",
        "    logging.info(f\"Model saved to: {model_path}\")\n",
        "    logging.info(f\"Best hyperparameters: {best_config.BEST_PARAMS_PATH}\")\n",
        "    logging.info(\"=\" * 70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c4acd7ef0944392a5df24a871a667a9",
            "7c5d2b8a39bc4e3c8e40c2957aa9b63d",
            "fb2236f2ad5f46ba93fc0fdc786056d2",
            "5b4fe311e19f4e50a6d59a3a9a966040",
            "15118888aa7b464a9e2577c3ff8dea1a",
            "6f11b58370ba47d6a02dcf7fe0539d60",
            "095ea811292143a1a22f02d8e4d6941a",
            "7c711892958b4b9496b4222f1d611f95",
            "d57ceb4225e343adbe938e7dd5f91657",
            "918454d08f314ef0ab6f291892a1cf3c",
            "0312f68c33b545d3a8e1bd3f4310b865",
            "f469b1ece53e414d9b8405b7f53898ef",
            "4a6c6191bcbb4b9aa0f7d7decb104b23",
            "5af60f0719b64dec9c888a01f892c766",
            "551ca829c2c24f328c092cd159e0fe75",
            "427f3f220f5c4f768e8a2863e10e68c5",
            "f672655873574b499e96e7aaa7846376",
            "2f0027a029cf4438b4640cd25bde11a1",
            "13e3b4d2fabb40e5bffe9d85dc59da39",
            "936f009c31254c2a9879e1d7402e3e93",
            "5119f58087d34263be6348e782ea5858",
            "8551b446a9d4438d8173cb426feb4b3e",
            "844716b0a90e46a0b80e9904a867e1ce",
            "5cf94b09efd949bd9249cf4a4d68c3bd",
            "fa4e9549a19f4487b5aeefc234ecab4d",
            "99710795dbb045279f7752ff0ec9e5f9",
            "d6c8741770d44ee19f791f78218f681d",
            "2222d4d3f9a24a61b13960adb44429f7",
            "e53360a223614d53af7435df196997cd",
            "38daf208c2094d3b8b9c612edf49a2e5",
            "700c1b2585ec461a92e382f82a1a13bc",
            "d2c7040d11d5471fb054fb3abecaf315",
            "2646a0743a0b4c16bd2214435f3b43b9",
            "c9bf57ab8edd464984baf227938cf317",
            "539845dba27a459ba1d70936fba131b5",
            "4fbda50bfb0e4d6d88d750e9d67c5f1d",
            "8d1bb4a98e0e4890a2af4d3ea0a546fe",
            "f69dae6df8c7452db0c9b008e99176a8",
            "91c8e42974f9425f86e512cc0fbae7ea",
            "8153c9e72335443197f0b279eb2f5d7f",
            "af6be7684e33431aa01f0d5fca5c7ab4",
            "368200953d3b477cb777e8a47d85a9af",
            "a7850b8b0cd942fc951f882d22b86703",
            "112a6e876796451cab7c551a6cf016d2"
          ]
        },
        "id": "CST9OKddqIK4",
        "outputId": "57f4f13a-dcb2-472a-90e6-99ce83dcbda1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-24 16:57:45,528 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,529 - INFO - BERT INTENT CLASSIFICATION PIPELINE\n",
            "2025-11-24 16:57:45,530 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,530 - INFO - Model: dbmdz/bert-base-italian-xxl-cased\n",
            "2025-11-24 16:57:45,531 - INFO - Features enabled:\n",
            "2025-11-24 16:57:45,531 - INFO -   - Focal Loss: True\n",
            "2025-11-24 16:57:45,532 - INFO -   - Class Weights: True\n",
            "2025-11-24 16:57:45,532 - INFO -   - Priority Scores: True\n",
            "2025-11-24 16:57:45,533 - INFO -   - Label Smoothing: True\n",
            "2025-11-24 16:57:45,533 - INFO -   - Mixed Precision: True\n",
            "2025-11-24 16:57:45,534 - INFO - ======================================================================\n",
            "\n",
            "2025-11-24 16:57:45,534 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,535 - INFO - LOADING DATASET\n",
            "2025-11-24 16:57:45,535 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,550 - INFO - ✓ Loaded 4021 samples\n",
            "2025-11-24 16:57:45,553 - INFO - \n",
            "11 intents found:\n",
            "2025-11-24 16:57:45,554 - INFO -   Ordini.Richiesta_Stato_Consegna                    :  763 (18.98%)\n",
            "2025-11-24 16:57:45,554 - INFO -   ComingSoon.Contabilità.Informazioni                :  620 (15.42%)\n",
            "2025-11-24 16:57:45,555 - INFO -   ComingSoon.Procedure.Ordini_Informazioni           :  496 (12.34%)\n",
            "2025-11-24 16:57:45,555 - INFO -   Generico.Richiesta_Generica                        :  464 (11.54%)\n",
            "2025-11-24 16:57:45,555 - INFO -   Problemi.Lettura_Device                            :  381 ( 9.48%)\n",
            "2025-11-24 16:57:45,556 - INFO -   Problemi.Alimentazione_Device                      :  357 ( 8.88%)\n",
            "2025-11-24 16:57:45,557 - INFO -   ComingSoon.Problemi.Autenticazione_Smarrimento_Blo :  285 ( 7.09%)\n",
            "2025-11-24 16:57:45,558 - INFO -   Procedure.Accettazione_Materiale_Problemi          :  224 ( 5.57%)\n",
            "2025-11-24 16:57:45,558 - INFO -   Problemi.Software_Device                           :  221 ( 5.50%)\n",
            "2025-11-24 16:57:45,559 - INFO -   NOMATCH                                            :  118 ( 2.93%)\n",
            "2025-11-24 16:57:45,564 - INFO - \n",
            "✓ Train/Val: 3417 | Test: 604\n",
            "2025-11-24 16:57:45,588 - INFO - \\Starting hyperparameter optimization...\n",
            "2025-11-24 16:57:45,588 - INFO - \\Training final model with best hyperparameters...\n",
            "2025-11-24 16:57:45,588 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,589 - INFO - TRAINING FINAL MODEL\n",
            "2025-11-24 16:57:45,589 - INFO - ======================================================================\n",
            "2025-11-24 16:57:45,589 - INFO - Using optimized hyperparameters:\n",
            "2025-11-24 16:57:45,590 - INFO -   LR=4.76e-05, BS=24, WD=0.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c4acd7ef0944392a5df24a871a667a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f469b1ece53e414d9b8405b7f53898ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "844716b0a90e46a0b80e9904a867e1ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-24 16:57:48,293 - INFO - Training Fold FINAL...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9bf57ab8edd464984baf227938cf317"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-24 16:57:51,759 - INFO - ✓ Class balance weights: 0.500 - 2.000\n",
            "2025-11-24 16:57:53,885 - INFO - ✓ Priority weights: 1.100 - 1.925\n",
            "2025-11-24 16:57:53,885 - INFO - ✓ Combined weights (α=0.78)\n",
            "2025-11-24 16:57:53,886 - INFO - ✓ Final weights: 0.677 - 1.752\n",
            "2025-11-24 16:57:54,059 - INFO - Using Focal Loss (γ=1.3798296530795757, smoothing=0.09242568547841506)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1806' max='1935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1806/1935 02:36 < 00:11, 11.54 it/s, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.672700</td>\n",
              "      <td>0.398074</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.806496</td>\n",
              "      <td>0.783163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.295600</td>\n",
              "      <td>0.350473</td>\n",
              "      <td>0.836257</td>\n",
              "      <td>0.830040</td>\n",
              "      <td>0.830532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.197500</td>\n",
              "      <td>0.377643</td>\n",
              "      <td>0.818713</td>\n",
              "      <td>0.813934</td>\n",
              "      <td>0.803499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.104600</td>\n",
              "      <td>0.409620</td>\n",
              "      <td>0.850877</td>\n",
              "      <td>0.851962</td>\n",
              "      <td>0.843673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.505578</td>\n",
              "      <td>0.818713</td>\n",
              "      <td>0.817687</td>\n",
              "      <td>0.812710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.055500</td>\n",
              "      <td>0.461739</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.843050</td>\n",
              "      <td>0.843845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>0.532822</td>\n",
              "      <td>0.839181</td>\n",
              "      <td>0.836462</td>\n",
              "      <td>0.829863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.552957</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.839728</td>\n",
              "      <td>0.832825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.019200</td>\n",
              "      <td>0.538714</td>\n",
              "      <td>0.856725</td>\n",
              "      <td>0.856416</td>\n",
              "      <td>0.844802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.583954</td>\n",
              "      <td>0.850877</td>\n",
              "      <td>0.850190</td>\n",
              "      <td>0.837790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.019500</td>\n",
              "      <td>0.598992</td>\n",
              "      <td>0.853801</td>\n",
              "      <td>0.851447</td>\n",
              "      <td>0.844918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.585619</td>\n",
              "      <td>0.853801</td>\n",
              "      <td>0.852729</td>\n",
              "      <td>0.842333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.589992</td>\n",
              "      <td>0.850877</td>\n",
              "      <td>0.850083</td>\n",
              "      <td>0.838894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.607439</td>\n",
              "      <td>0.850877</td>\n",
              "      <td>0.849805</td>\n",
              "      <td>0.837973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-24 17:00:31,634 - INFO - Fold FINAL: Best F1 = 0.8564\n",
            "2025-11-24 17:00:32,708 - INFO - ✓ Model saved to italian_intent_model_optimized2\n",
            "2025-11-24 17:00:33,109 - INFO - Final model training complete. Val F1: 0.8564\n",
            "2025-11-24 17:00:33,110 - INFO - Model saved to: italian_intent_model_optimized2\n",
            "2025-11-24 17:00:33,124 - INFO - \\Evaluating on test set...\n",
            "2025-11-24 17:00:33,126 - INFO - \n",
            "======================================================================\n",
            "2025-11-24 17:00:33,126 - INFO - FINAL EVALUATION ON TEST SET\n",
            "2025-11-24 17:00:33,126 - INFO - ======================================================================\n",
            "2025-11-24 17:00:33,127 - INFO - Loading inference model from italian_intent_model_optimized2 to cuda...\n",
            "2025-11-24 17:00:34,199 - INFO - ✓ Model loaded successfully.\n",
            "2025-11-24 17:00:34,200 - INFO - Running inference on 604 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Batch:   0%|          | 0/26 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "OPTForSequenceClassification.forward() got an unexpected keyword argument 'token_type_ids'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4225512374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4225512374.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\Evaluating on test set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     final_f1 = evaluate_on_test_set(\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mbest_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_optimized2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     )\n",
            "\u001b[0;32m/tmp/ipython-input-3742551436.py\u001b[0m in \u001b[0;36mevaluate_on_test_set\u001b[0;34m(config, df_test, model_path, label2id, id2label, num_labels, text_column, report_suffix)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Get predictions with confidences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     pred_labels, pred_ids, confidences, all_probs = pipeline.predict_batch(\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3742551436.py\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(self, texts, batch_size, return_confidences)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# Get probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OPTForSequenceClassification.forward() got an unexpected keyword argument 'token_type_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "zlZahmQEyd9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stakeholder utternaces report"
      ],
      "metadata": {
        "id": "YrP0iY1qk-wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_stakeholder_report(config, model_path, input_csv_path, output_csv_path):\n",
        "    df_new = pd.read_csv(input_csv_path)\n",
        "\n",
        "    if 'UserUtterance' in df_new.columns:\n",
        "        texts = df_new['UserUtterance'].astype(str).tolist()\n",
        "    else:\n",
        "        texts = df_new.iloc[:, 0].astype(str).tolist()\n",
        "\n",
        "    pipeline = InferencePipeline(model_path=model_path)\n",
        "\n",
        "    print(f\"Running inference on {len(texts)} new sentences...\")\n",
        "\n",
        "    pred_labels, pred_ids, confidences, all_probs = pipeline.predict_batch(\n",
        "        texts,\n",
        "        batch_size=32,\n",
        "        return_confidences=True,\n",
        "        temperature=1.5,\n",
        "        threshold=0.65\n",
        "    )\n",
        "\n",
        "    report_df = pd.DataFrame({\n",
        "        'User_Sentence': texts,\n",
        "        'Predicted_Intent': pred_labels,\n",
        "        'Confidence_Score': confidences\n",
        "    })\n",
        "\n",
        "    report_df['Model_Certainty'] = report_df['Confidence_Score'].apply(\n",
        "        lambda x: 'High' if x > 0.8 else ('Medium' if x > 0.6 else 'Low (Check Manually)')\n",
        "    )\n",
        "\n",
        "    report_df = report_df[[\n",
        "        'User_Sentence',\n",
        "        'Predicted_Intent',\n",
        "        'Model_Certainty',\n",
        "        'Confidence_Score'\n",
        "    ]]\n",
        "\n",
        "    report_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Report generated: {output_csv_path}\")\n",
        "    return report_df\n",
        "\n",
        "# --- EXECUTION ---\n",
        "# Assumes you have your config and trained model path ready\n",
        "# model_path = \"models/italian_intent_model_final_v3\" # Update this to your actual path\n",
        "generate_stakeholder_report(config, model_path, \"user_utterance_test.csv\", \"stakeholder_review_v1.csv\")"
      ],
      "metadata": {
        "id": "a8D6x48AoZwM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "ec6f23e6-5699-404c-83e7-82271d1f8bd2",
        "collapsed": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading inference model from italian_intent_model to cuda...\n",
            "Model loaded successfully.\n",
            "Running inference on 294 new sentences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Batch: 100%|██████████| 10/10 [00:00<00:00, 28.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report generated: stakeholder_review_v1.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         User_Sentence  \\\n",
              "0          stop quelle però mi servono le ho scaricate   \n",
              "1              non più manco a chiamare così il numero   \n",
              "2                     devo sollecitare una riparazione   \n",
              "3    quello che quello che mostra i numeri durante ...   \n",
              "4    Non mi funziona la convalida delle vincite del...   \n",
              "..                                                 ...   \n",
              "289             guardi Ho un problema con la stampante   \n",
              "290  il terminale del Lotto quando inserisco la sch...   \n",
              "291                     il terminale del Lotto fischia   \n",
              "292  cosa €3,50 ti devo dare e sono Eccoli qua Gius...   \n",
              "293                           quello della grati Vinci   \n",
              "\n",
              "                                      Predicted_Intent       Model_Certainty  \\\n",
              "0                      Ordini.Richiesta_Stato_Consegna                  High   \n",
              "1                                              NOMATCH  Low (Check Manually)   \n",
              "2                          Generico.Richiesta_Generica                  High   \n",
              "3                          Generico.Richiesta_Generica                Medium   \n",
              "4                              Problemi.Lettura_Device                  High   \n",
              "..                                                 ...                   ...   \n",
              "289                        Generico.Richiesta_Generica                  High   \n",
              "290  ComingSoon.Problemi.Autenticazione_Smarrimento...                  High   \n",
              "291                            Problemi.Lettura_Device                  High   \n",
              "292                                            NOMATCH                Medium   \n",
              "293                                            NOMATCH  Low (Check Manually)   \n",
              "\n",
              "     Confidence_Score  \n",
              "0            0.873126  \n",
              "1            0.519890  \n",
              "2            0.949710  \n",
              "3            0.668279  \n",
              "4            0.906829  \n",
              "..                ...  \n",
              "289          0.954317  \n",
              "290          0.804300  \n",
              "291          0.856151  \n",
              "292          0.697643  \n",
              "293          0.487383  \n",
              "\n",
              "[294 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc26c3b7-02d5-4f20-b9cf-6081dbd5d884\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Sentence</th>\n",
              "      <th>Predicted_Intent</th>\n",
              "      <th>Model_Certainty</th>\n",
              "      <th>Confidence_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stop quelle però mi servono le ho scaricate</td>\n",
              "      <td>Ordini.Richiesta_Stato_Consegna</td>\n",
              "      <td>High</td>\n",
              "      <td>0.873126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>non più manco a chiamare così il numero</td>\n",
              "      <td>NOMATCH</td>\n",
              "      <td>Low (Check Manually)</td>\n",
              "      <td>0.519890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>devo sollecitare una riparazione</td>\n",
              "      <td>Generico.Richiesta_Generica</td>\n",
              "      <td>High</td>\n",
              "      <td>0.949710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>quello che quello che mostra i numeri durante ...</td>\n",
              "      <td>Generico.Richiesta_Generica</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0.668279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Non mi funziona la convalida delle vincite del...</td>\n",
              "      <td>Problemi.Lettura_Device</td>\n",
              "      <td>High</td>\n",
              "      <td>0.906829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>guardi Ho un problema con la stampante</td>\n",
              "      <td>Generico.Richiesta_Generica</td>\n",
              "      <td>High</td>\n",
              "      <td>0.954317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>il terminale del Lotto quando inserisco la sch...</td>\n",
              "      <td>ComingSoon.Problemi.Autenticazione_Smarrimento...</td>\n",
              "      <td>High</td>\n",
              "      <td>0.804300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>il terminale del Lotto fischia</td>\n",
              "      <td>Problemi.Lettura_Device</td>\n",
              "      <td>High</td>\n",
              "      <td>0.856151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>cosa €3,50 ti devo dare e sono Eccoli qua Gius...</td>\n",
              "      <td>NOMATCH</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0.697643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>quello della grati Vinci</td>\n",
              "      <td>NOMATCH</td>\n",
              "      <td>Low (Check Manually)</td>\n",
              "      <td>0.487383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc26c3b7-02d5-4f20-b9cf-6081dbd5d884')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc26c3b7-02d5-4f20-b9cf-6081dbd5d884 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc26c3b7-02d5-4f20-b9cf-6081dbd5d884');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-81ffb127-2a16-4c76-bd47-da7350879582\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81ffb127-2a16-4c76-bd47-da7350879582')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-81ffb127-2a16-4c76-bd47-da7350879582 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"generate_stakeholder_report(config, model_path, \\\"user_utterance_test\",\n  \"rows\": 294,\n  \"fields\": [\n    {\n      \"column\": \"User_Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 282,\n        \"samples\": [\n          \"Vorrei parlare con un operatore serio se al Lotto devi attendere un attimo perch\\u00e9 abbiamo un problema col macchinario No no io verio non ti ho raccontato di questo no non ti ho raccontato il finale ieri \\u00e8 stata una giornataccia alle 12:30 12:25 prendi la b\",\n          \"verificare il pacco\",\n          \"S\\u00ec Pronto Buonasera avrei bisogno della lista dei Gratta Vinci convalidati oggi nel nostro punto vendita \\u00e8 possibile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted_Intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"ComingSoon.Procedure.Ordini_Informazioni\",\n          \"Ordini.Richiesta_Stato_Consegna\",\n          \"Problemi.Software_Device\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model_Certainty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"High\",\n          \"Low (Check Manually)\",\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Confidence_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 285,\n        \"samples\": [\n          0.9254743456840515,\n          0.9591909050941467,\n          0.5666279792785645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}